[
  {
    "objectID": "posts/2024-05-14/index.html",
    "href": "posts/2024-05-14/index.html",
    "title": "Comparison of Metagenomics and Metatranscriptomics Tools: A Guide to Making the Right Choice",
    "section": "",
    "text": "Bioinformatics is an area where new analytical methods, tools, and pipelines are constantly emerging. Therefore, knowing which tools are most appropriate for your data is essential to ensure the high quality of analyses and reproducibility.\nWith the aim of providing an overview of the techniques and tools available for Metagenomics and Metatranscriptomics, both from a methodological and bioinformatics perspective, Terrón-Camero and collaborators (Terrón-Camero et al. 2022) conducted a series of comparisons between read classification tools such as QIIME2, MEGAN, mOTU, MetaPhAn, Kranken2, and others; and also provides pipelines to execute all of them in an automated manner, using Nextflow.\nThe authors provide some tips on how to proceed with read classification, and here is a short answer:\n\nFor shotgun metagenomics: Kraken2;\nFor 16S analysis: we recommend using the QIIME 2 tool when a low number of reads exists;\nAlso for 16S analysis: Kraken2 is efficient when the library was deeply sequenced.\nFor metatranscriptomics data: Kraken2 and Bracken.\n\nThe work also makes it very clear the need to perform filtering by applying a threshold to eliminate organisms with low abundance, thus reducing false positives.\nIn addition to the technical characteristics of the tools, the article also provides a comprehensive review of the influence of gut microbiota on various conditions that can affect humans, which further enhances the value of reading the paper.\n\n\n\n\nReferences\n\nTerrón-Camero, Laura C., Fernando Gordillo-González, Eduardo Salas-Espejo, and Eduardo Andrés-León. 2022. “Comparison of Metagenomics and Metatranscriptomics Tools: A Guide to Making the Right Choice.” Genes 13 (12): 2280. https://doi.org/10.3390/genes13122280."
  },
  {
    "objectID": "posts/2024-03-26/index.html",
    "href": "posts/2024-03-26/index.html",
    "title": "Cholesin: a new hormone discovered for controlling cholesterol levels in humans",
    "section": "",
    "text": "Energy metabolism is one of the most fascinating and complex subjects in human metabolism. For example, cholesterol metabolism involves many different hormones and has a major impact on many diseases, especially cardiovascular diseases. However, apart from being widely studied, pathways involving cholesterol and their effects on human tissues are not completely understood. Recently, a paper published by Hu and collaborators made a major breakthrough in the understanding of the regulation of cholesterol levels (Hu et al. 2024).\nIt is known that cholesterol regulates - and it is regulated by - many genes. The HGM-CoA reductase, the enzyme involved in the first step of the cholesterol synthesis pathway, is downregulated when blood cholesterol levels are high, in a negative feedback mechanism. However, Hu and collaborators observed that the decrease of both RNA and protein levels of HGM-CoA reductase in this scenario is rapidly followed by a recovery of the HGM-CoA reductase, indicating that a new factor can influence the cholesterol synthesis after the cholesterol absorption.\nResearchers were able to isolate a small plasma protein in mice fed with high levels of cholesterol. This protein was related to the human homolog gene C7orf50, which previously had no function associated with it but it is highly conserved between species. They decided to call this protein a new name: cholesin.\nThrough many experiments, researchers showed that cholesin is secreted by enterocytes through a mechanism mediated by NPC1L1 protein, a surface protein in enterocytes involved with cholesterol absorption. Also, they found two specific genetic variations near the end of the cholesin gene that are significantly associated with cholesterol levels in the blood. They studied 600 people and found that higher cholesin levels were linked to lower total and LDL cholesterol levels, but not to HDL cholesterol. Cholesin levels were also negatively associated with triglyceride levels and showed a strong relationship with APOB, a protein associated with cholesterol transport.\n\n\n\nGraphical abstract summarising the main findings from Hu et al, 2024 paper.\n\n\nThese findings suggest that cholesin may play a role in regulating cholesterol levels in the body. This raises new possibilities for the development of new treatments for conditions such as hypercholesterolemia and cardiovascular diseases.\n\n\n\n\nReferences\n\nHu, Xiaoli, Fengyi Chen, Liangjie Jia, Aijun Long, Ying Peng, Xu Li, Junfeng Huang, et al. 2024. “A Gut-Derived Hormone Regulates Cholesterol Metabolism.” Cell. https://doi.org/https://doi.org/10.1016/j.cell.2024.02.024."
  },
  {
    "objectID": "posts/2024-04-02/index.html",
    "href": "posts/2024-04-02/index.html",
    "title": "Redefining the treponemal history through pre-Columbian genomes from Brazil",
    "section": "",
    "text": "It’s no secret that human migration dynamics are one of the primary factors responsible for the introduction of infectious agents to different parts of the planet. Historically, venereal syphilis is known to have caused a devastating outbreak in Europe in the late 15th century, leading to the widely accepted hypothesis that Treponema pallidum subsp. pallidum was introduced to the Americas during the colonization events led by Christopher Columbus.\nContradictorily, based on fossil findings, paleontologists have been proposing the hypothesis that treponemal infections occurred in the Americas since pre-Columbian times. However, as these are only fossil findings, paleopathological evidence is often considered contradictory and unreliable.\nTo finally clarify this topic, a group of researchers with expertise in Paleontology, Molecular Biology, and Bioinformatics conducted a study recently published in Nature, titled “Redefining the treponemal history through pre-Columbian genomes from Brazil.”(Majander et al. 2024) In this study, 99 fossil specimens from an archaeological site called Jabuticabeira II, located in the Laguna region of Santa Catarina on the Brazilian coast, were examined. These fossils were searched for signs of periostitis, bone remodeling, and “moth-eaten” marks, which are classic indicators of treponemal infections. At the end of the screening, 12 specimens were from individuals with these pathologies; however, only 4, from different individuals, provided sufficient genomic data for subsequent analysis.\nShotgun genomic data were filtered using the Kraken tool, with its respective default database, revealing that among the sequenced material, there were reads belonging to the Treponema family. After several stages of genomic material enrichment for T. pallidum, it was possible to fully reconstruct the genome of three subspecies. The genomes were aligned with others available in public databases and subjected to molecular clock dating techniques, revealing that one of the sublineage genomes dated back to between 780 BC and 449 AD.\n\n\n\nCompiled results from Majander et al. 2024\n\n\nThe findings also identified numerous recombination events among Treponema subspecies, which are classically known as a key mechanism in bacterial evolution. Thus, the groundbreaking discovery of a pre-Columbian treponematosis, stemming from a combination of ancient pathogen genomics and the careful selection of archaeological samples, sheds light on the events leading to the emergence and spread of venereal syphilis and helps resolve the evolutionary factors responsible for the global success of the Treponema family.\n\n\n\n\nReferences\n\nMajander, Kerttu, Marta Pla-Díaz, Louis Du Plessis, Natasha Arora, Jose Filippini, Luis Pezo-Lanfranco, Sabine Eggers, Fernando González-Candelas, and Verena J. Schuenemann. 2024. “Redefining the Treponemal History Through Pre-Columbian Genomes from Brazil.” Nature 627 (8002): 182–88. https://doi.org/10.1038/s41586-023-06965-x."
  },
  {
    "objectID": "posts/2024-06-13/index.html",
    "href": "posts/2024-06-13/index.html",
    "title": "Convert database identifiers with biomaRt R package",
    "section": "",
    "text": "BioMart is an integral part of the Ensembl project, and it was designed to facilitate the access and retrieval of biological data. With BioMart, users can easily extract information about genes, proteins, and other genomic features, linking this data across various biological datasets. Its flexibility and ease of use make it an invaluable tool for bioinformaticians and biologists aiming to integrate and analyze large-scale biological data efficiently. BioMart is available through its web page, however, there’s the biomaRt R/Bioconductor package that can be used to access data programatically.\nIn this tutorial, we show how to make a simple query using the biomaRt R package.\n\ngene_list &lt;- read.table(\"~/genes.txt\", header = T, sep = \"\\t\")\n\nSuppose that we have a list of human peptides (Ensembl peptide IDs) and we want to retrieve their corresponding gene symbols.\n\nhead(gene_list)\n\n  ensembl_peptide_id\n1    ENSP00000330918\n2    ENSP00000364486\n3    ENSP00000436217\n4    ENSP00000364699\n5    ENSP00000432005\n6    ENSP00000436669\n\n\nWith biomaRt package, we can do that in 3 simple steps:\n\nlibrary(biomaRt)\n\n\nSet the ensembl channel:\n\n\nensembl &lt;- useMart(\"ENSEMBL_MART_ENSEMBL\")\n\nDepending on the type of data you want to collect (e.g., variants), there are other channels available. To list all channels available, use the listMarts() function.\n\nChoose a dataset (organism):\n\nFor human data, the dataset keyword is hsapiens_gene_ensembl. To access the keywords for other organisms, run the listDatasets() function.\n\nensembl &lt;- useDataset(dataset = \"hsapiens_gene_ensembl\", mart = ensembl)\n\n\nMake the query:\n\nBefore making the query, we need to know which attribute keywords are available at BioMart database. We can list the attributes available with the listAttributes() function. We also need to obtain the filter keywords by using the listFilters() function. In summary, the attributes are the ID keywords you want to retrieve and the filters are the ID keywords you’ll use to make the query.\nWith proper attributes and filters selected, you can pass them to the attributes and filters arguments from the getBM() function. If you have a specific list of identifiers to convert, like we do have from the gene_list dataframe, pass it to the values argument. If you do not provide anything to the values argument, the getBM() function will return all identifiers requested for the attributes provided on the chosen organism.\n\n# Dataframe with attributes\natt &lt;- listAttributes(ensembl)\n\n# Dataframe with filters\nfilters &lt;- listFilters(ensembl)\n\n# Make the query with getBM function\nids &lt;- getBM(attributes = c(\"hgnc_symbol\", \"ensembl_peptide_id\"),\n             filters = \"ensembl_peptide_id\",\n             values = gene_list$ensembl_peptide_id,\n             mart = ensembl)\n\nhead(ids)\n\n  hgnc_symbol ensembl_peptide_id\n1        PCK2    ENSP00000494029\n2        PCK2    ENSP00000496343\n3        PCK2    ENSP00000496102\n4        PCK2    ENSP00000494919\n5       FOXO1    ENSP00000368880\n6       PTPN2    ENSP00000320298\n\n\nAnd that’s it! You can make many different queries on the database identifiers provided by BioMart."
  },
  {
    "objectID": "posts/2024-03-14/index.html",
    "href": "posts/2024-03-14/index.html",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Seurat is undoubtedly the most used package for single-cell analysis. However, the single-cell field has changed towards new programming languages and packages (e.g., Scanpy), which leads to an issue regarding interoperability , i.e., the ability of software to exchange and make use of information. Here, we show how to quickly convert Seurat objects from ongoing projects to AnnData (Scanpy data object).\n\n\n\n\n\n\n\n\nlibrary(Seurat)\nlibrary(dplyr)\nlibrary(sceasy)\n\n# Setting Assay version 5\noptions(Seurat.object.assay.version = \"v5\")\n\n# Load the PBMC dataset - available at 10x datasets website\npbmc.data &lt;- Read10X(\n    data.dir = \"/Users/affaustino/Projects/UTILS/quarto_blog/data/filtered_gene_bc_matrices/hg19\")\n\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc_seurat &lt;- CreateSeuratObject(\n  counts = pbmc.data, project = \"pbmc3k\", min.cells = 3, min.features = 200)\n\n\n# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\npbmc_seurat[[\"percent_mt\"]] &lt;- PercentageFeatureSet(pbmc_seurat, pattern = \"^MT-\")\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\n\n\nOnce we have the Seurat object, we can quickly inspect its structure. Why should we do it? For education, it is nice to understand what slots will be kept over the conversion process.\n\npbmc_seurat\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\npbmc_seurat@assays\n\n$RNA\nAssay (v5) data with 13714 features for 2700 cells\nTop 10 variable features:\n ISG15, CPSF3L, MRPL20, ATAD3C, C1orf86, RER1, RP3-395M20.9, LRRC47,\nGPR153, TNFRSF25 \nLayers:\n counts, data, scale.data \n\n\n\n\n\nIn our experience, the SingleCellExperiment object works as an intermediate layer between Seurat and AnnData. In short, it will ensure that most of the data is maintained among formats.\n\npbmc_sce &lt;- as.SingleCellExperiment(\n    pbmc_seurat)\n\n\n\n\nFinally, we will use sceasy for converting SingleCellExperiment to Anndata. sceasy is a package that helps easily convert different single-cell data formats to each other. Converting to AnnData creates a file that can be directly used in cellxgene which is an interactive explorer for single-cell transcriptomics datasets.\n\nconvertFormat(pbmc_sce, from=\"sce\", to=\"anndata\",\n                       outFile='/Users/affaustino/Projects/UTILS/quarto_blog/data/pbmc.h5ad')\n\nAnnData object with n_obs × n_vars = 2700 × 13714\n    obs: 'nCount_RNA', 'nFeature_RNA', 'percent_mt'\n    var: 'name'\n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-14/index.html#loading-requirements",
    "href": "posts/2024-03-14/index.html#loading-requirements",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "library(Seurat)\nlibrary(dplyr)\nlibrary(sceasy)\n\n# Setting Assay version 5\noptions(Seurat.object.assay.version = \"v5\")\n\n# Load the PBMC dataset - available at 10x datasets website\npbmc.data &lt;- Read10X(\n    data.dir = \"/Users/affaustino/Projects/UTILS/quarto_blog/data/filtered_gene_bc_matrices/hg19\")\n\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc_seurat &lt;- CreateSeuratObject(\n  counts = pbmc.data, project = \"pbmc3k\", min.cells = 3, min.features = 200)\n\n\n# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\npbmc_seurat[[\"percent_mt\"]] &lt;- PercentageFeatureSet(pbmc_seurat, pattern = \"^MT-\")\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()"
  },
  {
    "objectID": "posts/2024-03-14/index.html#inspecting-object",
    "href": "posts/2024-03-14/index.html#inspecting-object",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Once we have the Seurat object, we can quickly inspect its structure. Why should we do it? For education, it is nice to understand what slots will be kept over the conversion process.\n\npbmc_seurat\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\npbmc_seurat@assays\n\n$RNA\nAssay (v5) data with 13714 features for 2700 cells\nTop 10 variable features:\n ISG15, CPSF3L, MRPL20, ATAD3C, C1orf86, RER1, RP3-395M20.9, LRRC47,\nGPR153, TNFRSF25 \nLayers:\n counts, data, scale.data"
  },
  {
    "objectID": "posts/2024-03-14/index.html#converting-to-singlecellexperiment",
    "href": "posts/2024-03-14/index.html#converting-to-singlecellexperiment",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "In our experience, the SingleCellExperiment object works as an intermediate layer between Seurat and AnnData. In short, it will ensure that most of the data is maintained among formats.\n\npbmc_sce &lt;- as.SingleCellExperiment(\n    pbmc_seurat)"
  },
  {
    "objectID": "posts/2024-03-14/index.html#saving-as-anndata",
    "href": "posts/2024-03-14/index.html#saving-as-anndata",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Finally, we will use sceasy for converting SingleCellExperiment to Anndata. sceasy is a package that helps easily convert different single-cell data formats to each other. Converting to AnnData creates a file that can be directly used in cellxgene which is an interactive explorer for single-cell transcriptomics datasets.\n\nconvertFormat(pbmc_sce, from=\"sce\", to=\"anndata\",\n                       outFile='/Users/affaustino/Projects/UTILS/quarto_blog/data/pbmc.h5ad')\n\nAnnData object with n_obs × n_vars = 2700 × 13714\n    obs: 'nCount_RNA', 'nFeature_RNA', 'percent_mt'\n    var: 'name'\n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-12/index.html",
    "href": "posts/2024-03-12/index.html",
    "title": "Unveiling the Beginning of the Pandemic: The Transformative Role of Meta-Transcriptomics in Pathogen Identification",
    "section": "",
    "text": "The year 2020 will forever be remembered as the starting point of the COVID-19 pandemic, declared by the World Health Organization. A revolution in the speed of information generation marked this period, especially concerning the characterization of SARS-CoV-2 and the understanding of COVID-19.\n\n\n\nDesigned by Freepik\n\n\nIn just 12 days, from the hospital admission of a patient with characteristic COVID-19 symptoms to the publication in the prestigious journal Nature, the process of characterizing SARS-CoV-2 was remarkably efficient. In the study titled A New Coronavirus Associated with Human Respiratory Disease in China by Wu and collaborators (Wu et al. 2020), an advanced analytical method took center stage: meta-transcriptomics.\nTo better comprehend the pathogen infecting the patient, researchers employed high-coverage meta-transcriptomic sequencing through the Illumina MiniSeq platform. The biological sample from bronchoalveolar lavage fluid underwent de novo contig assembly, revealing a 30,474-nucleotide sequence closely related to the SARS-like coronavirus genome found in bats (CoV) and recorded in the GenBank.\nThe identified virus was named WH-Human 1 coronavirus (WHCV). Analysis of the viral sequence not only allowed for the inference of the transmission route but also uncovered mutations in the receptor-binding domain (RBD) of the SPIKE protein. This mutation was crucial, enabling the viral lineage to bind to the ACE2 protein and thus infect human cells. Additionally, the research traced the evolutionary events that gave rise to the virus later known as SARS-CoV-2.\nThis study stands as a remarkable example of how contemporary sequencing techniques, combined with careful analysis of biological data tools, play a vital role in the early detection of pathogens and the timely identification of agents capable of triggering local or global outbreaks.\nStay updated on metatranscriptomics, metagenomics, NGS, pathogens, virus, and COVID-19, and discover how science is unveiling the secrets behind global health threats.\n\n\n\n\nReferences\n\nWu, F., S. Zhao, B. Yu, and et al. 2020. “A New Coronavirus Associated with Human Respiratory Disease in China.” Nature 579: 265–69. https://doi.org/10.1038/s41586-020-2008-3."
  },
  {
    "objectID": "posts/2024-05-23/index.html",
    "href": "posts/2024-05-23/index.html",
    "title": "A link between the brain and the immune system",
    "section": "",
    "text": "The brain and the immune system are intricately connected, with recent research uncovering many pathways through which they interact. For example, The blood-brain barrier (BBB) regulates immune cell entry, while microglia mediate neuroinflammation in response to injury or infection. Recent discoveries of brain lymphatic vessels highlight direct brain-immune communication. Cytokines from immune cells and neurotransmitters from the brain create a bidirectional communication loop. Dysregulation in this connection is linked to neurodegenerative diseases like Alzheimer’s and multiple sclerosis, with chronic neuroinflammation playing a significant role.\n\n\n\nDesigned by Freepik.\n\n\nBy investigating how peripheral immune signals communicate with the brain via the vagal-nerve axis, researchers found a novel pathway through which the central nervous system modulate inflammatory processes. The accelerated publication authored by Li et al. (Jin et al. 2024) uncovers a body-to-brain neural circuit that plays a crucial role in regulating immune responses. They identified vagal neurons that are tightly connected to to pro-inflammatory and anti-inflammatory signals, transmitting inflammatory information to neurons in the brainstem. They also showed that the body-to-brain neural circuit’s has the ability to monitor and modulate the development of an inflammatory response, maintaining a balance between pro- and anti-inflammatory states. Additionally, the removal of this circuit during an innate immune challenge leads to unregulated and out-of-control inflammatory responses, while its activation can effectively reduce the pro-inflammatory state and promote anti-inflammatory responses. This circuit, particularly the Nucleus of the Solitary Tract neurons, acts as a biological rheostat controlling the extent of peripheral inflammatory responses through positive and negative feedback modulation on immune cells. These are new and important findings that have direct potential therapeutic implications for immune disorders, including autoimmune diseases, cytokine storm, toxic shock, and hyperactive immune states, by pharmacologically targeting this circuit. Therefore, the brain’s ability to transform the course of an immune response offers new possibilities for modulating a wide range of immune disorders, providing insights into combating dysregulated immune states and related diseases.\n\n\n\nDesigned by Freepik.\n\n\n\nReferences\n\nJin, H., M. Li, E. Jeong, et al. 2024. “A Body–Brain Circuit That Regulates Body Inflammatory Responses.” Nature. https://doi.org/10.1038/s41586-024-07469-y."
  },
  {
    "objectID": "posts/2024-02-27/index.html",
    "href": "posts/2024-02-27/index.html",
    "title": "Are you aware about RNA sequencing analysis?",
    "section": "",
    "text": "Imagem de DC Studio no Freepik\n\n\nSequencing technologies have revolutionized our understanding of human and other organisms’ biology. By having access to the transcriptome, one can have insights about the cellular functional alterations in different metabolic scenarios. From gene expression data, various analyses can be conducted, including:\n🧬 Differential expression analysis, to compare the expression levels of genes in case-control scenarios, making possible the identification of biomarkers and gene signatures;\n🔍 Functional enrichment analysis and gene set enrichment analysis (GSEA), to understand the impact of transcriptional alterations in cellular pathways and metabolic context;\n🤝 Co-expression analysis, to gather gene modules collectively expressed in a given condition;\n🔄 Protein-protein interaction networks, to understand how gene targets interact with each other in a functional and/or physical way;\n📊 Expression deconvolution, to infer cell type proportions from curated reference panels;\n🔗 Construction of regulatory networks, to understand how regulatory elements, such as transcription factors and non-coding RNAs, impact the transcriptional profile of a given condition.\nHere in Lexanomics, we have extensive experience in preprocessing RNA-Seq data by using gold-standard bioinformatics tools and protocols, which can help you to increase the impact of your research. Let’s advance together! 🚀 #Lexanomics #RNAseq #Bioinformatics #Research"
  },
  {
    "objectID": "posts/2024-05-09/index.html",
    "href": "posts/2024-05-09/index.html",
    "title": "Improving single-cell projects: Generative models for data imputation",
    "section": "",
    "text": "From (He et al. 2024)\n\n\nIn the previous post, we mentioned how deep-learning and generative approaches are revolutionizing genomics and single-cell studies.\nToday, we talk about another model that has a distinct purpose called MIDAS (mosaic integration and knowledge transfer). MIDAS is designed to handle and improve data integration across different single-cell modalities, e.g., RNA-Seq, ATAC-Seq, and CITE-seq or ADT (antibody-derived tags).\nThat sounds fancy. But what is the purpose of this approach?\nWell, single-cell studies are often limited by data sparsity, i.e., zeros in the count matrices. These so-called “gaps” in the data can dramatically reduce the biological insights related to a specific disease or condition. In this context, MIDAS shines as a way to effectively integrate multimodal data or even generate data modality layers for improving downstream analysis. Yes, I said generate.\nIn this study, the authors demonstrate how the method performs to fulfill this data mosaic. Not surprisingly, the generated layers seem to improve cell clustering and highlight cellular heterogeneity at a fine-grained level in a PBMC dataset. Further, the authors pushed the boundaries and mentioned that MIDAS can even help detect rare proteins in B cells (e.g., CD20). Other cell markers were also brought to attention such as CD3 and CD4 (T-cell markers) observed in two B subclusters. Intriguing.\nAnyhow, if you are a researcher and you facing issues analyzing your single-cell project - cough, cough low cell counts - I would suggest adding MIDAS-like methods to your workflow.\nYet, remember generative models are still biased and sometimes can lead to misinterpretations. Maybe a before-and-after imputation approach could be a nice way to go… I leave it to you, dear bioinformatician.\n\n\n\nFrom (He et al. 2024)\n\n\n\nReferences\n\nHe, Zhen, Shuofeng Hu, Yaowen Chen, Sijing An, Jiahao Zhou, Runyan Liu, Junfeng Shi, et al. 2024. “Mosaic Integration and Knowledge Transfer of Single-Cell Multimodal Data with MIDAS.” Nature Biotechnology, January. https://doi.org/10.1038/s41587-023-02040-y."
  },
  {
    "objectID": "posts/2024-05-02/index.html",
    "href": "posts/2024-05-02/index.html",
    "title": "Gut microbiome composition: link between sports performance and protein absorption?",
    "section": "",
    "text": "From (Fritz et al. 2024)\n\n\nProteins are the building blocks of nutrition, indispensable for bone and muscle metabolism. Adequate intake not only maintains health but also bolsters sports performance. However, recent studies have shed light on the intricate relationship between high-dose protein intake and potential intestinal inflammation, such as inflammatory bowel disease. While most proteins are digested in the small intestine, about 10% remain undigested, undergoing further breakdown by gut bacteria in the large intestine. This process, known as proteolysis, produces byproducts like ammonia and biogenic amines, which may exacerbate intestinal irritations.\nAthletes, with their heightened physical demands, often require double the daily protein intake. Yet, crafting precise nutritional strategies becomes paramount, especially for those in endurance or strength training programs. Balancing protein consumption with other macronutrients becomes a nuanced dance, complicating the formulation of universal recommendations. Seeking to optimize protein intake quality among athletes, a recent study set out to evaluate the impact of protein supplementation with and without prebiotics and fermented herbal probiotics on the gut microbiome.\nTwenty elite male water polo players participated, divided into Control and Intervention groups. Both groups received a daily 250 ml dose of vegan protein shake over a 31-day period. However, the Intervention group received an additional supplement comprising prebiotics and a fermented probiotic herbal product for 30 days alongside the vegan protein. Stool samples were collected before and after the intervention, and the genetic material was sequenced using a NextSeq2000 platform to analyze the gut microbiome composition.\nThroughout the study, no significant differences in macronutrient intake were observed between the groups or over time. However, the Intervention group exhibited notable improvements in various metrics related to body composition, including fat-free mass, skeletal muscle mass, and arm circumference, alongside reductions in body fat metrics. These changes correlated with alterations in the gut microbiota, particularly an increase in Bacteroidetes and a decrease in Firmicutes. Notably, bacteria producing short-chain fatty acids (SCFAs) like butyrate underwent significant changes, potentially influencing muscle mass positively. SCFAs have been linked to improved metabolism and reduced inflammation, both crucial for sustaining muscle health during rigorous training.\nIn conclusion, vegan protein supplementation, coupled with prebiotics and probiotics, proved beneficial for enhancing body composition among elite water polo players. The observed increase in skeletal muscle mass in the Intervention group suggests a synergistic relationship between protein supplementation and gut microbiota modulation. This is supported by the rise in SCFA-producing bacteria, hinting at improved muscle metabolism. Furthermore, elevated levels of mean corpuscular hemoglobin in the blood indicate enhanced metabolic activity within muscle cells, further bolstering the link between gut health and athletic performance.\n\n\n\nFrom (Fritz et al. 2024)\n\n\n\nReferences\n\nFritz, Péter, Réka Fritz, Pál Bóday, Ádám Bóday, Emese Bató, Péter Kesserű, and Csilla Oláh. 2024. “Gut Microbiome Composition: Link Between Sports Performance and Protein Absorption?” Journal of the International Society of Sports Nutrition 21 (1): 2297992. https://doi.org/10.1080/15502783.2023.2297992."
  },
  {
    "objectID": "posts/2024-06-04/index.html",
    "href": "posts/2024-06-04/index.html",
    "title": "Are a good or a bad guy? Identifying malignant cells using Numbat",
    "section": "",
    "text": "Teng Gao et al. (2022)\n\n\nDistinguishing malignant cells in a single-cell project can be a very time-consuming task. Particularly, malignant cells are heterogeneous and often display misleading expression signatures, which can be further obscure by tumor microenvironment or treatment features. In addition, some malignant cells are closely related to their normal counterparts (e.g., lymphoma).\nHow can we define malignant then? For this purpose, researchers have leveraged copy number variation (CNV) analysis, i.e., considering that only malignant cells should display these somatic events. A fair assumption.\nNowadays, many software statistically infers CNV load using single-cell transcriptomics data, such as InferCNV or CopyKAT. However, while these methods are useful, we can point out a few bottlenecks in their assumptions. Essentially, these methods assume that gene expression changes can be indicative of underlying CNVs. Further, InferCNV relies heavily on the accurate identification of reference (normal) cells. If the reference cells are not correctly annotated, this can lead to incorrect CNV inferences. CopyKAT detection is limited to CNV events based on changes in read depth across the genome. Finally, both methods are not suitable for analyzing rare subclone structures, i.e., they expected expanded subclones that share similar genotypes.\nFortunately, new methods can leverage supplementary data or distinct statistical assumptions. On this note, we would like to introduce, Numbat. Numbat can be used to:\n\nDetect allele-specific copy number variations from scRNA-seq and spatial transcriptomics;\nDifferentiate tumor versus normal cells in the tumor microenvironment;\nInfer the clonal architecture and evolutionary history of profiled tumors.\n\nNumbat integrates haplotype information obtained from population-based phasing with allele and expression signals to enhance the detection of copy number variations from scRNA-seq. Cool, but what that means?!\nIn short, Numbat capitalizes on the allele imbalance approach to determine expected deviations caused by CNV events, i.e., an allele that deviates from normal proportion (1:1 ratio of paternal and maternal copies). This is done by phasing the single-cell reads using reference panels, such as 1000G and TOPMed. We could think about it as a “fine-mapping” step that shows single-nucleotide polymorphisms proportion across the single-cell reads. Therefore, alleles displaying imbalance proportions should be derived from CNV events. Did you gotcha it?\nNow you have the principle, we can think this model is expanded into the haplotype level (multiple SNPs inherited together), and it incorporates expression changes related to genes across distinct cell populations. The distinct cell populations are essentially pseudobulk matrices- the authors mentioned that it was a way to overcome sparse coverage in scRNA-seq data. To note, it is a fairly common strategy for enhanced signal detection in single-cell studies.\nThus, Numbat’s model can jointly understand changes in the expression level considering how likely these changes are associated with CNV-related events. It is not only about expression fold-change deviations across probabilistic states but also about whether these deviations are supported by phased data on the pseudobulk level. What does that bring to the table?\nThe authors provide a few examples and validations displaying the value of their model (Teng Gao et al. 2022). But, for me, it considerably decreases subjectivity in selecting malignant cells (or even subclone structures) in my data. For instance, we are not using a reference based on annotated cells, which are very prone to human error, but a population-wise reference. Also, it potentially elucidates rare subclone structures by incorporating a maximum-likelihood step to capture evolutionary relationships between single cells.\nBut, what do you think bioinformaticians? Read the paper and, please feel free to reach out!\n\n\n\nTeng Gao et al. (2022)\n\n\n\nReferences\n\nTeng Gao, Ruslan Soldatov, Hirak Sarkar, Adam Kurkiewicz, Evan Biederstedt, Po-Ru Loh, and Peter Kharchenko. 2022. “Haplotype-Aware Analysis of Somatic Copy Number Variations from Single-Cell Transcriptomes.” Nature Biotechnology. https://www.nature.com/articles/s41587-022-01468-y."
  },
  {
    "objectID": "posts/2024-03-02/index.html",
    "href": "posts/2024-03-02/index.html",
    "title": "Jumping genetic element getting in the way of primates tail evolution",
    "section": "",
    "text": "It is of common knowledge that humans and monkeys share great similarities regarding their genomes. And, if most monkeys have tails, what happend to ours? This is the central question Xia and colleagues (Xia et al. 2024) try to answer.\nAfter comparing the genomic sequences across primates, the researchers found a mobile genetic element called Alu only inserted on the gene TBXT of apes, a gene that encodes for a transcription factor associated with tail development in mammals. Alu elements have the ability of “teleporting” and fixating in other genome regions and therefore they are very important to diversify genome sequences. The Alu element insertion found in apes leads to an alternative splicing event, resulting in the production of a shortened form of the TBXT gene. Humans express both the full-length and the shortened versions of TBXT gene.\n\n\n\nEvolution of tails in primates. Figure from Xia et al, 2024.\n\n\nTo test their hypothesis, researchers engineered mice to express these two gene versions and they observed that, in this scenario, mice exhibit a lack of a tail or a shortened tail, similar to the tail-loss phenotype in hominoids. However, for mice engineered to have only the shortened version of TBXT gene died during the embryonic development. This suggests that the evolution of tail loss in hominoids may have been associated with an adaptive trade-off, where the loss of the tail conferred evolutionary advantages but also increased the risk of neural tube defects.\n\n\n\nFrom SMBC comics (https://www.smbc-comics.com/).\n\n\nThis research is a great example of comparative genome analysis, common in the Bioinformatics area. Do you need help in comparing genomes? Talk to the Lexanomics team!\n\n\n\n\nReferences\n\nXia, B., W. Zhang, G. Zhao, et al. 2024. “On the Genetic Basis of Tail-Loss Evolution in Humans and Apes.” Nature 626: 1042–48. https://doi.org/10.1038/s41586-024-07095-8."
  },
  {
    "objectID": "posts/2024-04-25/index.html",
    "href": "posts/2024-04-25/index.html",
    "title": "Population genetics meets immunotherapy",
    "section": "",
    "text": "Accounting for TCR diversity across human populations\n\n\nArguably, the immune system displays one of the highest complexities of any biological process in evolution. In humans, its ability to respond to pathogens spans multiple layers, such as adaptive and innate immunity, which are sometimes mediated by complex genetic arrangements, e.g., the T cell receptor (TCR) repertoire. TCRs are a fundamental component in adaptive immunity and have promising applications in immunotherapy.\nHowever, the genetic determinates behind TCR diversity and its consequences for biomedical research remain insufficiently defined. In particular, Corcoran et al (2023) have highlighted TCR genetic variability across different human populations, including African, East Asian, South Asian, and European.\n\n\n\n\nFrom (Corcoran et al. 2023)\n\n\n\n\nBased on the Corcoran study, genetic differences in the TCR genes can be found within every individual, other than identical twins, and every population. In total, the authors discovered 175 new gene variants, including three Neanderthal-derived introgressions. Particularly, Neanderthal-derived introgression seems to affect the interaction between specific TCR locus with butyrophilin-like molecule 3 (BTNL3) in modern Eurosian populations. BTNL3 modulates Vg4+ T cell activity in intestinal tissues and ultimately can lead to inflammation in Celiac disease, an autoimmune disorder. Alternatively, the authors showcase several variants that are associated with prognostic markers in multiple tumor types, including head and neck cancer. Finally, these findings provides insights into the mechanisms of immune regulation and potentially shows how to prioritize T-cell clonotypes immunotherapy applications, i.e., accounting for genetic background and treatment risk.\nFor those related to TCR research: Have you considered these aspects in your investigations? These might be fundamental questions to pursue in admixture populations.\n\n\n\nFrom (Corcoran et al. 2023)\n\n\n\n\nReferences\n\nCorcoran, Martin, Mark Chernyshev, Marco Mandolesi, Sanjana Narang, Mateusz Kaduk, Kewei Ye, Christopher Sundling, et al. 2023. “Archaic Humans Have Contributed to Large-Scale Variation in Modern Human T Cell Receptor Genes.” Immunity 56 (3): 635–652.e6."
  },
  {
    "objectID": "posts/2024-05-21/index.html",
    "href": "posts/2024-05-21/index.html",
    "title": "gnomAD: 1,000,000 individuals variation reference",
    "section": "",
    "text": "From time to time, large consortiums release valuable datasets to the public. gnomAD is one such example. Following the release of gnomAD’s exome and genome data, a new dataset comprising nearly one million patients (Sun et al. 2024) is now available for analysis and research.\n\n\n\nOperários (Workers) from brazilian painter, Tarsila do Amaral.\n\n\nThe article explores the genetic differences in over 980,000 people from various backgrounds, offering a valuable resource for understanding rare genetic variations. By studying the genetic data, researchers found millions of unique genetic changes, providing insights into how these variations are distributed among different populations. This extensive dataset, called the RGC Million Exome (RGCME), includes a diverse mix of participants and follows a standardized approach to data collection, making it easier for scientists to study gene functions, diseases, and genetic differences among populations.\nThe study also identified genes that are crucial for normal cell function but may not be linked to known diseases because they are essential. By analyzing specific gene regions and protein domains intolerant to mutations, researchers gained a better understanding of how genetic changes can affect protein functions and potentially lead to diseases. This detailed analysis helps researchers prioritize genetic variants for further study and better interpret their impact on health and diseases.\nFurthermore, the research focused on identifying harmful genetic changes that can disrupt protein functions and lead to diseases. By using advanced computer tools to analyze the genetic data, researchers discovered hidden genetic changes that can affect how proteins work and contribute to diseases. These findings not only expand our knowledge of rare genetic variations but also support efforts in precision medicine by uncovering how genetic differences can influence health outcomes in diverse populations.\n\n\n\nOperários (Workers) from brazilian painter, Tarsila do Amaral.\n\n\n\nReferences\n\nSun, K. Y., X. Bai, S. Chen, et al. 2024. “A Deep Catalogue of Protein-Coding Variation in 983,578 Individuals.” Nature. https://doi.org/10.1038/s41586-024-07556-0."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lexanomics Blog",
    "section": "",
    "text": "Convert database identifiers with biomaRt R package\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nJun 13, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nAre a good or a bad guy? Identifying malignant cells using Numbat\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMay 28, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nYet another tip for speeding up DEG analysis on Seurat\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMay 28, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nA link between the brain and the immune system\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 23, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\ngnomAD: 1,000,000 individuals variation reference\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 21, 2024\n\n\nDiego M. Coelho\n\n\n\n\n\n\n\n\n\n\n\n\nHow non-coding variants can explain developmental disorders\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 16, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nComparison of Metagenomics and Metatranscriptomics Tools: A Guide to Making the Right Choice\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 14, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nImproving single-cell projects: Generative models for data imputation\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 9, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nscGPT: A foundation model for single-cell genomics that got it! (The Right Stuff).\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 7, 2024\n\n\nDiego Coelho\n\n\n\n\n\n\n\n\n\n\n\n\nGut microbiome composition: link between sports performance and protein absorption?\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMay 2, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nPopulation genetics meets immunotherapy\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nApr 25, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nAn automatic and biological-driven approach for defining “roots” on Monocle3\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 18, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nHow much does it cost a Bioinformatician? - Asking ChatGPT\n\n\n\n\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nApr 18, 2024\n\n\nDiego M. Coelho\n\n\n\n\n\n\n\n\n\n\n\n\nClinical application of bronchoalveolar lavage fluid metagenomics next-generation sequencing in cancer patients with severe pneumonia\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nApr 11, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a PPI network from a list of differentially expressed genes\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 9, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nBasic taxonomic classification of long and short reads with Kraken2\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 4, 2024\n\n\nDiego Gomes\n\n\n\n\n\n\n\n\n\n\n\n\nRedefining the treponemal history through pre-Columbian genomes from Brazil\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nApr 2, 2024\n\n\nDiego Gomes\n\n\n\n\n\n\n\n\n\n\n\n\nParallelization tips on Seurat\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMar 28, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nCholesin: a new hormone discovered for controlling cholesterol levels in humans\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 26, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nThe butterfly effect: lncRNAs in the evolutionists’ sights\n\n\n\n\n\n\nawesome science\n\n\nevolution\n\n\nlncRNA\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nData interoperability for single-cell analysis\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMar 14, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling the Beginning of the Pandemic: The Transformative Role of Meta-Transcriptomics in Pathogen Identification\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nWhy to sequence the DNA?\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nJumping genetic element getting in the way of primates tail evolution\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 3, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysing the cell transcriptional profile at the single-cell resolution\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 29, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nA new look into microorganisms by the lens of metagenomics\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nAre you aware about RNA sequencing analysis?\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\nIara Souza\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-05-16/index.html",
    "href": "posts/2024-05-16/index.html",
    "title": "How non-coding variants can explain developmental disorders",
    "section": "",
    "text": "Coding variants, especially single-nucleotide variants, are genetic alterations occurring within the coding region of the genes. They are widely studied in human genomics given their relationship to human diseases, including rare Mendelian disorders and complex diseases. The effects of coding variants that result in a change of amino acids (e.g., missense and nonsense variants) can be promptly identified in the protein sequence, impacting the protein function. However, what are the effects of non-coding variants in human diseases?\n\n\n\nFigure from Pérez-Agustín, Pinsach-Abuin, and Pagans (2020) showing the impact of cis-non-coding variants on the mRNA.\n\n\nDevelopmental disorders are mental and/or physical disabilities typically starting in infancy. About 30-40% of individuals with DD are associated with a genetic diagnosis, indicating that the condition has also a multifactor background. In a new pre-print, Lord et al. analyzed the data of probands and relatives from Genomics England 100,000 Genomes and investigated the genetic architecture of DD (Lord et al. 2023). In the study, the researchers focused on identifying rare non-coding variants in trans (inherited from the alternate parent to the coding variant) that could potentially act as the “second hit” in compound heterozygous genotypes associated with developmental disorders. They defined and analyzed various non-coding regulatory regions associated with the 793 identified recessive genes, including intronic regions, 5’UTRs, 3’UTRs, and candidate upstream promoter regions.\nAfter stringent bioinformatic filtering and quality control measures, the researchers identified rare non-coding variants in these regulatory regions that passed their criteria. These non-coding variants were assessed for their potential regulatory impact on gene expression and function. The study found that a subset of proband-variant pairs (36.3%) had at least one rare non-coding variant in trans that met the quality filters and could potentially contribute to the pathogenicity of the genotype.\nFurthermore, the researchers conducted functional testing using RNA sequencing to evaluate the impact of these non-coding variants on gene expression and splicing. This approach provided insights into how the identified non-coding variants may disrupt regulatory elements and contribute to the pathogenesis of developmental disorders in conjunction with coding variants in recessive genes. In addition, this study sheds light on the potential role of non-coding variants on the physiopathology of other conditions.\n\n\n\nFigure from Pérez-Agustín, Pinsach-Abuin, and Pagans (2020) showing the impact of cis-non-coding variants on the mRNA.\n\n\n\nReferences\n\nLord, Jenny, Carolina J Oquendo, Alexandra Martin-Geary, Alexander JM Blakes, Elena Arciero, Silvia Domcke, Anne-Marie Childs, et al. 2023. “Non-Coding Variants Are a Rare Cause of Recessive Developmental Disorders in Trans with Coding Variants.” medRxiv 2023.06.23.23291805. https://doi.org/https://doi.org/10.1101/2023.06.23.23291805.\n\n\nPérez-Agustín, Adrian, Mel·lina Pinsach-Abuin, and Sara Pagans. 2020. “Role of Non-Coding Variants in Brugada Syndrome.” International Journal of Molecular Sciences 21. https://doi.org/10.3390/ijms21228556."
  },
  {
    "objectID": "posts/2024-04-11/index.html",
    "href": "posts/2024-04-11/index.html",
    "title": "Clinical application of bronchoalveolar lavage fluid metagenomics next-generation sequencing in cancer patients with severe pneumonia",
    "section": "",
    "text": "Graphical abstract summarising the main findings from Wang et al, 2024 paper.\n\n\nSevere pneumonia presents a significant challenge for cancer patients, often complicating timely and accurate diagnosis of underlying pathogens. Conventional diagnostic approaches can be sluggish and may overlook crucial infections, particularly in individuals with compromised immune systems. However, the advent of metagenomic next-generation sequencing (mNGS) is revolutionizing diagnostic protocols by expediting accurate identification and bypassing the need for additional clinical assessments such as Gram staining, serum immunological tests, G tests, GM tests, and PCR tests.\nIn a study targeting cancer patients grappling with severe pneumonia, Wang et al. (Wang et al. 2024) harnessed mNGS to scrutinize lung fluid in conjunction with standard culture techniques. Their findings underscored mNGS’s superior efficacy in detecting infections, even discerning multiple microorganisms simultaneously. Notably, it excelled in identifying elusive pathogens like Streptococcus pneumoniae and Aspergillus, which often elude traditional diagnostic methods.\nThe research demonstrated that mNGS results prompted treatment adjustments for over half of the patients, leading to improved clinical outcomes. By furnishing clinicians with precise information regarding the causative agents, mNGS facilitated targeted antibiotic or antifungal therapy selection.\nAlthough mNGS shows great promise, it does have some drawbacks. It can be expensive, and there are still technical issues to work out. Also, because it’s very sensitive, it can’t always tell if something is contamination, colonization, or an actual infection. Still, the study shows that mNGS can really help doctors diagnose and treat infections in cancer patients with severe pneumonia. This new tool helps healthcare workers handle these serious illnesses better, which should lead to better outcomes in the future.\n\n\n\n\nReferences\n\nWang, Chao, Xiaojuan Yin, Wenqing Ma, Li Zhao, Xuhong Wu, Nan Ma, Yuepeng Cao, et al. 2024. “Clinical Application of Bronchoalveolar Lavage Fluid Metagenomics Next-Generation Sequencing in Cancer Patients with Severe Pneumonia.” Respiratory Research 25 (1): 68. https://doi.org/10.1186/s12931-023-02654-5."
  },
  {
    "objectID": "posts/2024-04-16/index.html",
    "href": "posts/2024-04-16/index.html",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "There are many reasons why a researcher wants to perform pseudotime analysis on single-cell datasets, including but not limited to cellular differentiation, developmental stages, and disease progression.\nCurrently, we can leverage many packages for dealing with such analysis. We could roughly categorize them into approaches based on user-defined roots and model-based roots. Note that roots are the starting point of the pseudotime analysis, i.e., the algorithm will sort the cells and their transcriptional profiles based on that specific data point. Therefore, it is a VERY crucial step in pseudotime!\nOn that note, Monocle3 is a well-known package for performing pseudotime analysis. It should be included in the “user-defined” category, i.e., it relies on a knowledge-driven selection. To aid bioinformaticians in root selection, we can leverage distinct models to give us hints. Today, we will talk about CytoTRACE, a package for measuring differentiation scores in single-cell datasets. CytoTRACE is based on the simple observation that transcriptional diversity—the number of genes expressed in a cell—decreases during differentiation. Thus, we can assume that cells predicted as less differentiated are the best candidates for pseudotime roots. Check it out!\n\n\n\n\n\n\n\n\n\n\n\nlibrary(Seurat)\nlibrary(SeuratWrappers)\nlibrary(monocle3)\nlibrary(UCell)\nlibrary(dbscan)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Loading the CytoTRACE code.\nsource(here::here(\"./data/CytoTRACE.R\"))\nsource(here::here(\"./data/plotCytoTRACE.R\"))\n\n\n\n\nHere, we will leverage data from Vázquez-García et al (2022). This data was subset for only 20.000 cells, including malignant and TME cells. Particularly, this dataset was CD45+ and CD45− flow-sorted, i.e., we can easily distinguish between putative malignant, epithelial cells and TME-related cells.\n\nseurat_object &lt;- readRDS(file = here::here(\"./data/Ovarian_main_cluster_object.20k.RDS\"))\n\n\nDimPlot(\n  seurat_object,\n  group.by = \"Sort\"\n)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will subset NK cells based on lineage markers. It is fairly easy to do once we know which genes to look at. We will provide a small, but accurate list for major cell types.\n\ncell_lineage_markers &lt;- list(\n  \"T-Cells\" = c(\"CD3D\",\"CD3E\",\"CD4\",\"CD8A\",\"CD8B\"), \n  \"NK_cells\" = c(\"NCAM1\",\"KLRG1\",\"FCGR3A\",\"NKG7\",\"GNLY\",\"CD160\"), \n  \"B/Plasma_cells\" = c(\"CD19\",\"MS4A1\",\"CD79A\",\"CD79B\",\"SDC1\",\"MZB1\",\"XBP1\",\"JCHAIN\"), \n  \"Myeloid\" = c(\"LYZ\",\"S100A8\",\"S100A9\",\"CD68\",\"CD14\",\"C1QB\",\"C1QC\"), \n  \"Endothelial\" = c(\"PECAM1\",\"VWF\",\"ENG\",\"MCAM\"), \n  \"Fibroblast\" = c(\"FAP\",\"PDPN\",\"COL1A2\",\"DCN\",\"COL3A1\",\"COL6A1\"),\n  \"Epithelial\" = c(\"EPCAM\",\"MUC1\",\"ERBB2\",\"KRT8\",\"PGC\",\"GKN2\",\"SLC5A5\",\"FABP1\",\"KRT20\")\n)\n\n\nseurat_object &lt;- AddModuleScore_UCell(\n  seurat_object,\n  ncores = 8,\n  features = cell_lineage_markers) \n\n\nFeaturePlot(\n  seurat_object, \n  reduction = \"umap\", \n  label = TRUE,\n  ncol = 2,\n  features = paste0(\n    names(cell_lineage_markers), \"_UCell\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nAs expected the signature score derived from UCell can help us to annotate the distinct cell populations. The clusters #1, #7, and #15 are associated with NK and T-cells. This tutorial will consider that clusters #7 and #15 are populated by NK cells. Note, that cluster #15 displays both T and NK signatures, a common feature associated with NK/T-cells. However, we will ignore it for today :)\n\nnk_compartiment_object &lt;- subset(\n  seurat_object, subset = seurat_clusters %in% c(7, 15))\n\n\nnk_compartiment_counts &lt;- LayerData(\n    object = nk_compartiment_object, layer = \"counts\")\n\n\ncyto_results &lt;- CytoTRACE(nk_compartiment_counts)\n\n\nplotCytoTRACE(cyto_results)\n\n\n\n\n\n\n\n\n\n\n\nCytoTRACE will rank the cell based on differentiation score, values ranging from 0 (more differentiated) to 1 (less differentiated).\n\n# Extracting UMAP coordinates\nnk_compartiment_embeddings &lt;- Embeddings(\n  nk_compartiment_object[[\"umap\"]]\n)\n\n# Adding UMAP and CytoTRACE score on metadata\nnk_compartiment_object &lt;- AddMetaData(\n  nk_compartiment_object,\n  nk_compartiment_embeddings\n)\n\nnk_compartiment_object@meta.data[['CytoTRACE']] &lt;- \n  cyto_results$CytoTRACE\n\nNext, we will leverage dbscan for selecting highly-dense clusters with CyTRACE scores higher or equal to 0.9.\n\n# Creating a data.frame with embeddings and CytoTrace score\ndata &lt;- nk_compartiment_object@meta.data[, c(\"umap_1\", \"umap_2\", \"CytoTRACE\")]\ndata &lt;- data %&gt;%\n  mutate(\n    filtered = ifelse(CytoTRACE &gt;= 0.9, \"Yes\", \"No\") \n  )\n\n\n# Subsetting only CytoTRACE higher than 0.9 (less differentiated)\nfiltered_data &lt;- data %&gt;%\n  filter(filtered == \"Yes\") %&gt;%\n  select(umap_1, umap_2)\n\n# Choose eps and minPts based on your dataset characteristics\nclustering &lt;- dbscan(filtered_data, eps = 0.5, minPts = 5)\n\n\n# Calculate k-nearest neighbors distance as a proxy for density\ndistances &lt;- kNNdist(filtered_data, k = 5)  # You might want to adjust this based on the density you expect\n\n# Add distances to your data frame\nfiltered_data$local_density = 1 / distances  # Inverse of distance to indicate density\n\n# Determine the candidate/representative for each cluster\ncluster_representatives &lt;- data.frame()\n\nfor (i in unique(clustering$cluster)) {\n  if (i &gt; 0) {  \n    \n    # Only consider non-noise clusters\n    cluster_data &lt;- filtered_data[clustering$cluster == i,]\n    \n    # Select the data point with the maximum local density\n    representative_index &lt;- which.max(cluster_data$local_density)\n    cluster_representatives &lt;- rbind(cluster_representatives, cluster_data[representative_index, ])\n  }\n}\n\nknitr::kable(cluster_representatives)\n\n\n\n\n\n\n\n\n\n\n\numap_1\numap_2\nlocal_density\n\n\n\n\nSPECTRUM-OV-009_S1_CD45P_RIGHT_UPPER_QUADRANT_AATCGACAGACGGTTG-1\n-7.502961\n3.156997\n15.18489\n\n\n\n\n\n\nggplot(data = data, aes(x = umap_1, y = umap_2)) +\n  geom_point(aes(color = filtered), alpha = 0.5) +\n  geom_point(data = cluster_representatives, color = \"black\", size = 5, shape = 17) +\n  scale_color_manual(values = c(\"grey\", \"blue\", \"black\"), labels = c(\"No\", \"Yes\", \"Candidate\")) +\n  labs(title = \"UMAP Plot\", x = \"UMAP 1\", y =\"UMAP 2\", color = \"Has high CytoTRACE score?\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nOkey dokey! Now we have a decent candidate (black triangle) to be used as a root! We can finally focus on pseudotime analysis with Monocle3.\n\n\n\n\nmonocle_object &lt;- as.cell_data_set(nk_compartiment_object)\nmonocle_object &lt;- cluster_cells(monocle_object)\nmonocle_object &lt;- learn_graph(monocle_object)\n\n\n# This will print out an unrooted trajectory\np0 &lt;- plot_cells(\n  monocle_object,\n  cell_size = 2,\n  label_groups_by_cluster = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np0\n\n\n\n\n\n\n\n\n\n\n\n\nmonocle_object &lt;- order_cells(\n  monocle_object, root_cells = row.names(cluster_representatives)) # Voilà. We can add the cell_id here.\n\n\np1 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"pseudotime\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np2 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"CytoTRACE\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np1 + p2\n\n\n\n\n\n\n\n\nDone! We now have a basic workflow for defining pseudotime roots without manual intervention. The CytoTRACE + Monocle3 idea was originally published here.\n\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin22.4.0 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRblas.dylib \nLAPACK: /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] dplyr_1.1.2                 ggplot2_3.4.2              \n [3] dbscan_1.1-11               UCell_2.6.2                \n [5] monocle3_1.3.4              SingleCellExperiment_1.23.0\n [7] SummarizedExperiment_1.31.1 GenomicRanges_1.53.1       \n [9] GenomeInfoDb_1.37.2         IRanges_2.35.2             \n[11] S4Vectors_0.39.1            MatrixGenerics_1.13.1      \n[13] matrixStats_1.0.0           Biobase_2.61.0             \n[15] BiocGenerics_0.47.0         SeuratWrappers_0.3.19      \n[17] Seurat_4.9.9.9045           SeuratObject_4.9.9.9084    \n[19] sp_2.0-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.21        splines_4.3.0           later_1.3.1            \n  [4] bitops_1.0-7            tibble_3.2.1            R.oo_1.25.0            \n  [7] polyclip_1.10-4         fastDummies_1.7.3       lifecycle_1.0.3        \n [10] rstatix_0.7.2           rprojroot_2.0.3         globals_0.16.2         \n [13] lattice_0.21-8          MASS_7.3-60             backports_1.4.1        \n [16] magrittr_2.0.3          plotly_4.10.2           rmarkdown_2.23         \n [19] yaml_2.3.7              remotes_2.4.2.1         httpuv_1.6.11          \n [22] sctransform_0.3.5       spam_2.9-1              spatstat.sparse_3.0-2  \n [25] reticulate_1.35.0       cowplot_1.1.1           pbapply_1.7-2          \n [28] minqa_1.2.5             RColorBrewer_1.1-3      abind_1.4-5            \n [31] zlibbioc_1.47.0         Rtsne_0.16              purrr_1.0.2            \n [34] R.utils_2.12.2          RCurl_1.98-1.12         GenomeInfoDbData_1.2.10\n [37] ggrepel_0.9.3           irlba_2.3.5.1           listenv_0.9.0          \n [40] spatstat.utils_3.0-3    terra_1.7-39            goftest_1.2-3          \n [43] RSpectra_0.16-1         spatstat.random_3.1-5   fitdistrplus_1.1-11    \n [46] parallelly_1.36.0       ncdf4_1.21              leiden_0.4.3           \n [49] codetools_0.2-19        DelayedArray_0.27.10    tidyselect_1.2.0       \n [52] farver_2.1.1            viridis_0.6.4           lme4_1.1-34            \n [55] spatstat.explore_3.2-1  jsonlite_1.8.7          BiocNeighbors_1.19.0   \n [58] ellipsis_0.3.2          progressr_0.13.0        ggridges_0.5.4         \n [61] survival_3.5-5          tools_4.3.0             ica_1.0-3              \n [64] Rcpp_1.0.11             glue_1.6.2              gridExtra_2.3          \n [67] SparseArray_1.1.11      xfun_0.39               here_1.0.1             \n [70] withr_2.5.0             BiocManager_1.30.21.1   fastmap_1.1.1          \n [73] HiClimR_2.2.1           boot_1.3-28.1           fansi_1.0.4            \n [76] egg_0.4.5               digest_0.6.33           rsvd_1.0.5             \n [79] R6_2.5.1                mime_0.12               colorspace_2.1-0       \n [82] scattermore_1.2         tensor_1.5              spatstat.data_3.0-1    \n [85] R.methodsS3_1.8.2       utf8_1.2.3              tidyr_1.3.0            \n [88] generics_0.1.3          data.table_1.14.8       robustbase_0.99-0      \n [91] httr_1.4.6              htmlwidgets_1.6.2       S4Arrays_1.1.5         \n [94] uwot_0.1.16             pkgconfig_2.0.3         gtable_0.3.3           \n [97] lmtest_0.9-40           XVector_0.41.1          pcaPP_2.0-3            \n[100] htmltools_0.5.5         carData_3.0-5           dotCall64_1.0-2        \n[103] scales_1.2.1            png_0.1-8               knitr_1.43             \n[106] rstudioapi_0.15.0       reshape2_1.4.4          nlme_3.1-162           \n[109] nloptr_2.0.3            proxy_0.4-27            zoo_1.8-12             \n[112] stringr_1.5.0           KernSmooth_2.23-22      parallel_4.3.0         \n[115] miniUI_0.1.1.1          pillar_1.9.0            grid_4.3.0             \n[118] vctrs_0.6.3             RANN_2.6.1              ggpubr_0.6.0           \n[121] promises_1.2.0.1        car_3.1-2               xtable_1.8-4           \n[124] cluster_2.1.4           evaluate_0.21           mvtnorm_1.2-2          \n[127] cli_3.6.1               compiler_4.3.0          rlang_1.1.1            \n[130] crayon_1.5.2            leidenbase_0.1.25       ggsignif_0.6.4         \n[133] future.apply_1.11.0     labeling_0.4.2          plyr_1.8.8             \n[136] stringi_1.7.12          nnls_1.5                viridisLite_0.4.2      \n[139] deldir_1.0-9            BiocParallel_1.35.3     assertthat_0.2.1       \n[142] ccaPP_0.3.3             munsell_0.5.0           lazyeval_0.2.2         \n[145] spatstat.geom_3.2-4     Matrix_1.6-0            RcppHNSW_0.4.1         \n[148] patchwork_1.1.2         future_1.33.0           shiny_1.7.4.1          \n[151] ROCR_1.0-11             broom_1.0.5             igraph_1.5.1           \n[154] DEoptimR_1.1-0         \n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-04-16/index.html#loading-requirements",
    "href": "posts/2024-04-16/index.html#loading-requirements",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "library(Seurat)\nlibrary(SeuratWrappers)\nlibrary(monocle3)\nlibrary(UCell)\nlibrary(dbscan)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Loading the CytoTRACE code.\nsource(here::here(\"./data/CytoTRACE.R\"))\nsource(here::here(\"./data/plotCytoTRACE.R\"))"
  },
  {
    "objectID": "posts/2024-04-16/index.html#loading-pre-processed-seurat-object",
    "href": "posts/2024-04-16/index.html#loading-pre-processed-seurat-object",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "Here, we will leverage data from Vázquez-García et al (2022). This data was subset for only 20.000 cells, including malignant and TME cells. Particularly, this dataset was CD45+ and CD45− flow-sorted, i.e., we can easily distinguish between putative malignant, epithelial cells and TME-related cells.\n\nseurat_object &lt;- readRDS(file = here::here(\"./data/Ovarian_main_cluster_object.20k.RDS\"))\n\n\nDimPlot(\n  seurat_object,\n  group.by = \"Sort\"\n)"
  },
  {
    "objectID": "posts/2024-04-16/index.html#performing-basic-cell-type-annotation",
    "href": "posts/2024-04-16/index.html#performing-basic-cell-type-annotation",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "Next, we will subset NK cells based on lineage markers. It is fairly easy to do once we know which genes to look at. We will provide a small, but accurate list for major cell types.\n\ncell_lineage_markers &lt;- list(\n  \"T-Cells\" = c(\"CD3D\",\"CD3E\",\"CD4\",\"CD8A\",\"CD8B\"), \n  \"NK_cells\" = c(\"NCAM1\",\"KLRG1\",\"FCGR3A\",\"NKG7\",\"GNLY\",\"CD160\"), \n  \"B/Plasma_cells\" = c(\"CD19\",\"MS4A1\",\"CD79A\",\"CD79B\",\"SDC1\",\"MZB1\",\"XBP1\",\"JCHAIN\"), \n  \"Myeloid\" = c(\"LYZ\",\"S100A8\",\"S100A9\",\"CD68\",\"CD14\",\"C1QB\",\"C1QC\"), \n  \"Endothelial\" = c(\"PECAM1\",\"VWF\",\"ENG\",\"MCAM\"), \n  \"Fibroblast\" = c(\"FAP\",\"PDPN\",\"COL1A2\",\"DCN\",\"COL3A1\",\"COL6A1\"),\n  \"Epithelial\" = c(\"EPCAM\",\"MUC1\",\"ERBB2\",\"KRT8\",\"PGC\",\"GKN2\",\"SLC5A5\",\"FABP1\",\"KRT20\")\n)\n\n\nseurat_object &lt;- AddModuleScore_UCell(\n  seurat_object,\n  ncores = 8,\n  features = cell_lineage_markers) \n\n\nFeaturePlot(\n  seurat_object, \n  reduction = \"umap\", \n  label = TRUE,\n  ncol = 2,\n  features = paste0(\n    names(cell_lineage_markers), \"_UCell\")\n  )"
  },
  {
    "objectID": "posts/2024-04-16/index.html#subsetting-nk-compartment-for-cytotrace-analysis",
    "href": "posts/2024-04-16/index.html#subsetting-nk-compartment-for-cytotrace-analysis",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "As expected the signature score derived from UCell can help us to annotate the distinct cell populations. The clusters #1, #7, and #15 are associated with NK and T-cells. This tutorial will consider that clusters #7 and #15 are populated by NK cells. Note, that cluster #15 displays both T and NK signatures, a common feature associated with NK/T-cells. However, we will ignore it for today :)\n\nnk_compartiment_object &lt;- subset(\n  seurat_object, subset = seurat_clusters %in% c(7, 15))\n\n\nnk_compartiment_counts &lt;- LayerData(\n    object = nk_compartiment_object, layer = \"counts\")\n\n\ncyto_results &lt;- CytoTRACE(nk_compartiment_counts)\n\n\nplotCytoTRACE(cyto_results)"
  },
  {
    "objectID": "posts/2024-04-16/index.html#extracting-less-differentiated-nk-cells",
    "href": "posts/2024-04-16/index.html#extracting-less-differentiated-nk-cells",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "CytoTRACE will rank the cell based on differentiation score, values ranging from 0 (more differentiated) to 1 (less differentiated).\n\n# Extracting UMAP coordinates\nnk_compartiment_embeddings &lt;- Embeddings(\n  nk_compartiment_object[[\"umap\"]]\n)\n\n# Adding UMAP and CytoTRACE score on metadata\nnk_compartiment_object &lt;- AddMetaData(\n  nk_compartiment_object,\n  nk_compartiment_embeddings\n)\n\nnk_compartiment_object@meta.data[['CytoTRACE']] &lt;- \n  cyto_results$CytoTRACE\n\nNext, we will leverage dbscan for selecting highly-dense clusters with CyTRACE scores higher or equal to 0.9.\n\n# Creating a data.frame with embeddings and CytoTrace score\ndata &lt;- nk_compartiment_object@meta.data[, c(\"umap_1\", \"umap_2\", \"CytoTRACE\")]\ndata &lt;- data %&gt;%\n  mutate(\n    filtered = ifelse(CytoTRACE &gt;= 0.9, \"Yes\", \"No\") \n  )\n\n\n# Subsetting only CytoTRACE higher than 0.9 (less differentiated)\nfiltered_data &lt;- data %&gt;%\n  filter(filtered == \"Yes\") %&gt;%\n  select(umap_1, umap_2)\n\n# Choose eps and minPts based on your dataset characteristics\nclustering &lt;- dbscan(filtered_data, eps = 0.5, minPts = 5)\n\n\n# Calculate k-nearest neighbors distance as a proxy for density\ndistances &lt;- kNNdist(filtered_data, k = 5)  # You might want to adjust this based on the density you expect\n\n# Add distances to your data frame\nfiltered_data$local_density = 1 / distances  # Inverse of distance to indicate density\n\n# Determine the candidate/representative for each cluster\ncluster_representatives &lt;- data.frame()\n\nfor (i in unique(clustering$cluster)) {\n  if (i &gt; 0) {  \n    \n    # Only consider non-noise clusters\n    cluster_data &lt;- filtered_data[clustering$cluster == i,]\n    \n    # Select the data point with the maximum local density\n    representative_index &lt;- which.max(cluster_data$local_density)\n    cluster_representatives &lt;- rbind(cluster_representatives, cluster_data[representative_index, ])\n  }\n}\n\nknitr::kable(cluster_representatives)\n\n\n\n\n\n\n\n\n\n\n\numap_1\numap_2\nlocal_density\n\n\n\n\nSPECTRUM-OV-009_S1_CD45P_RIGHT_UPPER_QUADRANT_AATCGACAGACGGTTG-1\n-7.502961\n3.156997\n15.18489\n\n\n\n\n\n\nggplot(data = data, aes(x = umap_1, y = umap_2)) +\n  geom_point(aes(color = filtered), alpha = 0.5) +\n  geom_point(data = cluster_representatives, color = \"black\", size = 5, shape = 17) +\n  scale_color_manual(values = c(\"grey\", \"blue\", \"black\"), labels = c(\"No\", \"Yes\", \"Candidate\")) +\n  labs(title = \"UMAP Plot\", x = \"UMAP 1\", y =\"UMAP 2\", color = \"Has high CytoTRACE score?\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nOkey dokey! Now we have a decent candidate (black triangle) to be used as a root! We can finally focus on pseudotime analysis with Monocle3."
  },
  {
    "objectID": "posts/2024-04-16/index.html#preparing-monocle-object",
    "href": "posts/2024-04-16/index.html#preparing-monocle-object",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "monocle_object &lt;- as.cell_data_set(nk_compartiment_object)\nmonocle_object &lt;- cluster_cells(monocle_object)\nmonocle_object &lt;- learn_graph(monocle_object)\n\n\n# This will print out an unrooted trajectory\np0 &lt;- plot_cells(\n  monocle_object,\n  cell_size = 2,\n  label_groups_by_cluster = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np0"
  },
  {
    "objectID": "posts/2024-04-16/index.html#defining-pseudotime-root-based-on-differentiation-score",
    "href": "posts/2024-04-16/index.html#defining-pseudotime-root-based-on-differentiation-score",
    "title": "An automatic and biological-driven approach for defining “roots” on Monocle3",
    "section": "",
    "text": "monocle_object &lt;- order_cells(\n  monocle_object, root_cells = row.names(cluster_representatives)) # Voilà. We can add the cell_id here.\n\n\np1 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"pseudotime\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np2 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"CytoTRACE\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np1 + p2\n\n\n\n\n\n\n\n\nDone! We now have a basic workflow for defining pseudotime roots without manual intervention. The CytoTRACE + Monocle3 idea was originally published here.\n\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin22.4.0 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRblas.dylib \nLAPACK: /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] dplyr_1.1.2                 ggplot2_3.4.2              \n [3] dbscan_1.1-11               UCell_2.6.2                \n [5] monocle3_1.3.4              SingleCellExperiment_1.23.0\n [7] SummarizedExperiment_1.31.1 GenomicRanges_1.53.1       \n [9] GenomeInfoDb_1.37.2         IRanges_2.35.2             \n[11] S4Vectors_0.39.1            MatrixGenerics_1.13.1      \n[13] matrixStats_1.0.0           Biobase_2.61.0             \n[15] BiocGenerics_0.47.0         SeuratWrappers_0.3.19      \n[17] Seurat_4.9.9.9045           SeuratObject_4.9.9.9084    \n[19] sp_2.0-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.21        splines_4.3.0           later_1.3.1            \n  [4] bitops_1.0-7            tibble_3.2.1            R.oo_1.25.0            \n  [7] polyclip_1.10-4         fastDummies_1.7.3       lifecycle_1.0.3        \n [10] rstatix_0.7.2           rprojroot_2.0.3         globals_0.16.2         \n [13] lattice_0.21-8          MASS_7.3-60             backports_1.4.1        \n [16] magrittr_2.0.3          plotly_4.10.2           rmarkdown_2.23         \n [19] yaml_2.3.7              remotes_2.4.2.1         httpuv_1.6.11          \n [22] sctransform_0.3.5       spam_2.9-1              spatstat.sparse_3.0-2  \n [25] reticulate_1.35.0       cowplot_1.1.1           pbapply_1.7-2          \n [28] minqa_1.2.5             RColorBrewer_1.1-3      abind_1.4-5            \n [31] zlibbioc_1.47.0         Rtsne_0.16              purrr_1.0.2            \n [34] R.utils_2.12.2          RCurl_1.98-1.12         GenomeInfoDbData_1.2.10\n [37] ggrepel_0.9.3           irlba_2.3.5.1           listenv_0.9.0          \n [40] spatstat.utils_3.0-3    terra_1.7-39            goftest_1.2-3          \n [43] RSpectra_0.16-1         spatstat.random_3.1-5   fitdistrplus_1.1-11    \n [46] parallelly_1.36.0       ncdf4_1.21              leiden_0.4.3           \n [49] codetools_0.2-19        DelayedArray_0.27.10    tidyselect_1.2.0       \n [52] farver_2.1.1            viridis_0.6.4           lme4_1.1-34            \n [55] spatstat.explore_3.2-1  jsonlite_1.8.7          BiocNeighbors_1.19.0   \n [58] ellipsis_0.3.2          progressr_0.13.0        ggridges_0.5.4         \n [61] survival_3.5-5          tools_4.3.0             ica_1.0-3              \n [64] Rcpp_1.0.11             glue_1.6.2              gridExtra_2.3          \n [67] SparseArray_1.1.11      xfun_0.39               here_1.0.1             \n [70] withr_2.5.0             BiocManager_1.30.21.1   fastmap_1.1.1          \n [73] HiClimR_2.2.1           boot_1.3-28.1           fansi_1.0.4            \n [76] egg_0.4.5               digest_0.6.33           rsvd_1.0.5             \n [79] R6_2.5.1                mime_0.12               colorspace_2.1-0       \n [82] scattermore_1.2         tensor_1.5              spatstat.data_3.0-1    \n [85] R.methodsS3_1.8.2       utf8_1.2.3              tidyr_1.3.0            \n [88] generics_0.1.3          data.table_1.14.8       robustbase_0.99-0      \n [91] httr_1.4.6              htmlwidgets_1.6.2       S4Arrays_1.1.5         \n [94] uwot_0.1.16             pkgconfig_2.0.3         gtable_0.3.3           \n [97] lmtest_0.9-40           XVector_0.41.1          pcaPP_2.0-3            \n[100] htmltools_0.5.5         carData_3.0-5           dotCall64_1.0-2        \n[103] scales_1.2.1            png_0.1-8               knitr_1.43             \n[106] rstudioapi_0.15.0       reshape2_1.4.4          nlme_3.1-162           \n[109] nloptr_2.0.3            proxy_0.4-27            zoo_1.8-12             \n[112] stringr_1.5.0           KernSmooth_2.23-22      parallel_4.3.0         \n[115] miniUI_0.1.1.1          pillar_1.9.0            grid_4.3.0             \n[118] vctrs_0.6.3             RANN_2.6.1              ggpubr_0.6.0           \n[121] promises_1.2.0.1        car_3.1-2               xtable_1.8-4           \n[124] cluster_2.1.4           evaluate_0.21           mvtnorm_1.2-2          \n[127] cli_3.6.1               compiler_4.3.0          rlang_1.1.1            \n[130] crayon_1.5.2            leidenbase_0.1.25       ggsignif_0.6.4         \n[133] future.apply_1.11.0     labeling_0.4.2          plyr_1.8.8             \n[136] stringi_1.7.12          nnls_1.5                viridisLite_0.4.2      \n[139] deldir_1.0-9            BiocParallel_1.35.3     assertthat_0.2.1       \n[142] ccaPP_0.3.3             munsell_0.5.0           lazyeval_0.2.2         \n[145] spatstat.geom_3.2-4     Matrix_1.6-0            RcppHNSW_0.4.1         \n[148] patchwork_1.1.2         future_1.33.0           shiny_1.7.4.1          \n[151] ROCR_1.0-11             broom_1.0.5             igraph_1.5.1           \n[154] DEoptimR_1.1-0         \n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-08/index.html",
    "href": "posts/2024-03-08/index.html",
    "title": "Why to sequence the DNA?",
    "section": "",
    "text": "There are many different DNA sequencing technologies, all of them with their potentialities. However, do you know some of the main use cases for DNA sequencing?\n\n\n\nDesigned by Freepik\n\n\n🧬 Genomic research: By sequencing the whole genome (WGS) or the exome (WES), one can understand the organism’s genetic architecture;\n💉 Medical diagnostics: DNA sequencing can identify mutations and variations associated with genetic disorders, allowing for early diagnosis and personalized treatment plans;\n💊 Pharmacogenomics: Understanding how an individual’s genetic makeup influences their response to drugs helps tailor medication plans for maximum efficacy and minimal side effects;\n🕵️‍♂️ Forensic analysis: DNA sequencing is used in forensic investigations to identify individuals, establish paternity, and solve criminal cases by analyzing biological evidence such as hair, blood, or saliva.\n👪 Ancestry and Genealogy: DNA sequencing, particularly in the form of consumer genetic testing, is used to trace familial and ancestral relationships, providing insights into personal heritage and ancestry;\n🦠 Microbial and environmental analysis: Sequencing the genomes of bacteria, viruses, and other microorganisms helps understand their biology and develop targeted treatments. Also, with DNA sequencing, it is possible to identify microorganisms in environmental samples, such as soil or water, helps monitor biodiversity, identify species presence, and assess ecosystem health;\n🦴 Evolutionary Biology: Sequencing the genome of viruses and bacteria allows us to develop more precise hypotheses regarding the spread of pathogens responsible for the development of infectious diseases. Also sequencing ancient DNA from fossils and archaeological remains contributes to our understanding of evolutionary processes and the history of life on Earth.\nThe Lexanomics team is experienced in all DNA sequencing analyses. If you want to know more about them, contact us! #DNAsequencing #Bioinformatics #Lexanomics 🧬🔬📊"
  },
  {
    "objectID": "posts/2024-02-29/index.html",
    "href": "posts/2024-02-29/index.html",
    "title": "Analysing the cell transcriptional profile at the single-cell resolution",
    "section": "",
    "text": "Single-cell RNA-seq analysis is a powerful technique used in biology and medicine to study the gene expression of individual cells within a population. Single-cell gene expression analysis and bulk RNA-seq differ primarily in the scale and resolution of the analysis. Single-cell gene expression analysis focuses on individual cells, providing insights into cellular heterogeneity and rare cell populations. In contrast, bulk RNA-seq measures the average gene expression of a population of cells, masking cellular diversity. Single-cell analysis requires specialized methods to isolate and analyze individual cells, while bulk RNA-seq is more straightforward and commonly used for analyzing gene expression in larger cell populations.\nBesides producing beautiful visualizations (La Manno et al. 2021), single-cell data has revolutionized the information regarding cell biology, with direct applications to the understanding of cell development and human diseases.\n\n\n\nt-SNE representation for cell types development in mouse brain. Figure from (La Manno et al. 2021).\n\n\nHere’s some use cases for single-cell data:\n\nCellular Heterogeneity 🧬: Understand the complex biological processes such as development, disease progression, and immune responses.\nDevelopmental Biology 🌱: Insights into the molecular mechanisms underlying cell differentiation and development.\nCancer Research 🦠: Study tumor heterogeneity, identify rare subpopulations of cells, and track the evolution of cancer cells over time or in response to treatment.\nNeuroscience 🧠: Map the cellular diversity of the brain, identify different cell types, and understand how they function in both healthy and diseased states.\nImmunology 🦠: Study immune cell diversity, activation states, and responses to stimuli.\nStem Cell Biology 🌱: Study the properties of stem cells, such as self-renewal and differentiation potential, and identify markers for specific cell types.\nDrug Discovery and Development 💊: Identify new drug targets, understand drug resistance mechanisms, and optimize drug development pipelines.\n\nSingle-cell opened a world to new discoveries. Do you need help with analysing single-cell data? Schedule a meeting with the Lexanomics consultants!\n\n\n\n\nReferences\n\nLa Manno, Gioele, Kimberly Siletti, Alessandro Furlan, Daniel Gyllborg, Elin Vinsland, Alejandro Mossi Albiach, Christoffer Mattsson Langseth, et al. 2021. “Molecular Architecture of the Developing Mouse Brain.” Nature 596 (7870): 92–96. https://doi.org/10.1038/s41586-021-03775-x."
  },
  {
    "objectID": "posts/2024-02-28/index.html",
    "href": "posts/2024-02-28/index.html",
    "title": "A new look into microorganisms by the lens of metagenomics",
    "section": "",
    "text": "Have you ever heard that a great percentage of our body composition comes from the microorganisms living with us? Recent research suggests a 1:1 ratio for the number of microorganisms and human cells in the body (Sender, Fuchs, and Milo 2016). We coexist with several species of microorganisms and, therefore, our physiology is greatly influenced by these tiny beings. But can we study them all at once?\n\n\n\nDesigned by Freepik\n\n\nYes! That’s when metagenomics comes to the rescue! Metagenomics is a relatively recent field of study within genetics and microbiology that involves the analysis of genetic material collected directly from human or environmental samples. The key principle behind metagenomics is the sequencing and analysis of DNA or RNA from an entire microbial community, without the need for isolating and culturing individual organisms. Here’s some applications for metagenomics:\nHuman Microbiome Research: 👩‍🔬 Metagenomics sheds light on the diverse microbial communities residing within us, influencing health, disease, and personalized medicine;\nClinical Diagnostics: 🏥 Rapid identification of pathogens in clinical samples aids in disease diagnosis, treatment, and surveillance, bolstering public health efforts;\nBiodiversity Conservation: 🦠Assess microbial diversity in threatened habitats, aiding in conservation planning and restoration efforts;\nEnsuring Food Safety: 🍽️ Detect foodborne pathogens, spoilage organisms, and authenticate food products, ensuring safety and quality;\nForensic Analysis: 🕵️‍♂️ Analyze microbial signatures associated with crime scenes, human remains, and environmental samples, enhancing forensic science capabilities;\nEnvironmental Microbiology: 🌍 Metagenomics unveils insights into ecosystems, aiding conservation efforts and sustainable resource management;\nBioremediation Solutions: 🛠️ Metagenomics identifies microbial candidates capable of degrading pollutants, paving the way for effective bioremediation strategies;\nAdvancing Agriculture: 🌾 Metagenomics guides precision farming practices, enhancing crop productivity, and fostering sustainable agriculture…\n… and many more! Really, the sky’s the limit for metagenomics applications. Do want help with metagenomics analyses? The Lexanomics team is here to help you! #Bioinformatics #Metagenomics #Lexanomics\n\n\n\n\nReferences\n\nSender, Ron, Shai Fuchs, and Ron Milo. 2016. “Are We Really Vastly Outnumbered? Revisiting the Ratio of Bacterial to Host Cells in Humans.” Cell 164 (3): 337–40. https://doi.org/https://doi.org/10.1016/j.cell.2016.01.013."
  },
  {
    "objectID": "posts/2024-03-19/index.html",
    "href": "posts/2024-03-19/index.html",
    "title": "The butterfly effect: lncRNAs in the evolutionists’ sights",
    "section": "",
    "text": "Flying insects have been starring the study of evolution. The story of how moths with darker color increased frequency in contrast to light color moths in the highly polluted 1900’s Manchester is a well-known example of the relationship of natural selection and evolution.\nProtein coding genes are the main subjects of evolutionary studies, since they are directly implicated into protein production. However, another class of genes might need more attention. This time, a mutant butterfly caught the researchers attention.\n\n\n\nHeliconius melpomene, a butterfly which was the subject of the studies. Image by wirestock on Freepik\n\n\nThe discovery of a mutant butterfly on eBay has led to a breakthrough in understanding how butterfly wings develop their diverse patterns of colors. Previously, a protein-encoding gene called cortex was thought to be responsible, but new research has revealed that a different gene, which produces an lncRNA, is the key regulator. Evolutionary biologists discovered that a long noncoding RNA (lncRNA) controls the color patterns in butterfly wings. They found this by studying white-winged Heliconius butterflies and disabling the lncRNA gene in painted lady butterflies, which resulted in white-winged offspring. This lncRNA also controls pigmentation in other butterfly species. Another team found similar results in buckeye butterflies, where CRISPR editing of the lncRNA affected wing color and seasonal changes in color. Additionally, researchers in Singapore found that a microRNA regulates black wing patterns in squinting bush brown butterflies (Trivedi 2021; Fandino et al. 2024).\nThese findings highlight the role of RNA, rather than proteins, in controlling visible traits in butterflies. This is the first time that long noncoding RNA (lncRNA) has been linked to the evolution of a visible trait in animals, suggesting that noncoding RNA plays a crucial role in genetic regulation.\n\n\n\n\nReferences\n\nFandino, Richard A., Noah K. Brady, Martik Chatterjee, Jeanne M. C. McDonald, Luca Livraghi, Karin R. L. van der Burg, Anyi Mazo-Vargas, Eirene Markenscoff-Papadimitriou, and Robert D. Reed. 2024. “The Ivory lncRNA Regulates Seasonal Color Patterns in Buckeye Butterflies.” bioRxiv. https://doi.org/10.1101/2024.02.09.579733.\n\n\nTrivedi, Y. 2021. “Surprise RNAs Solve Mystery of How Butterfly Wings Get Their Colorful Patterns.” Science 373 (6554): 1234–37. https://doi.org/10.1126/science.abcd1234."
  },
  {
    "objectID": "posts/2024-03-28/index.html",
    "href": "posts/2024-03-28/index.html",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "For the series on basic, but useful tips on single-cell analysis. We want to introduce parallelization using future for Seurat.\nFrequently a bioinformatician/computational biologist needs to test multiple parameters in a single-cell project, e.g., evaluating clustering resolutions. Although a conventional task, this procedure could take a while ranging from minutes to hours… It can get even worse if we talk about differential expressions analysis with well-known FindAllMarkers.\nLife is short, and I want my results. That being said, why not use parallelization? To our surprise, not many data analysts are familiar with the future package [1]. Furthermore, the future package is very handy for R package development - Yes, it is not limited to Seurat, you could incorporate it into your package/script.\n\n\n\n\n\n\n\n\nAs for Seurat, there are at least six (06) functions that were written to leverage future parallelization.\n\nNormalizeData\nScaleData -JackStraw\nFindMarkers*\nFindIntegrationAnchors\nFindClusters*\n\n*For teaching purposes we will focus only on these two functions.\n\n\n\nlibrary(Seurat)\nlibrary(dplyr)\nlibrary(future)\n\nPlease note that we need to establish what parallelization strategy (plan) will be used in our analysis. Also, we are running multiple processes in parallel which can dramatically increase the memory consumption. Be thoughtful about it.\n\n# Setting memory limit for 8Gb\noptions(future.globals.maxSize = 8000 * 1024^2)\n\n# Enabling parallelization\nplan(\"multicore\", workers = 4) # To the date, RStudio does not support parallelization. Run this script using Rscript command-line application.\n\nNext, we will load the PBMC dataset from 10X Genomics. Available here\n\npbmc_seurat &lt;- readRDS(file = \"path/to/pbmc_seurat.RDS\")\npbmc_seurat\n\n\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\n\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\npbmc_seurat &lt;- RunPCA(pbmc_seurat)\n\n\n\n\nAs mentioned, often a bioinformatician will evaluate with multiple clustering resolutions. In this tutorial, we will do such a task considering eight different thresholds.\n\npbmc_seurat &lt;- FindNeighbors(pbmc_seurat, dims = 1:10)\npbmc_seurat &lt;- FindClusters(pbmc_seurat, \n                            resolution = c(0.1, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0))\n\n\n\n\nFinally, we will execute the differential expression analysis.\n\npbmc_markers &lt;- FindAllMarkers(pbmc_seurat, only.pos = TRUE)\n\n\npbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    dplyr::filter(avg_log2FC &gt; 1)\n\n# A tibble: 2,830 × 7\n# Groups:   cluster [11]\n      p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 4.62e-91       1.08 0.954 0.609  6.33e-87 0       LDHB     \n 2 1.94e-89       2.11 0.517 0.124  2.66e-85 0       CCR7     \n 3 1.68e-52       1.76 0.396 0.117  2.30e-48 0       PRKCQ-AS1\n 4 9.77e-52       1.83 0.388 0.114  1.34e-47 0       LEF1     \n 5 1.77e-43       1.89 0.323 0.09   2.42e-39 0       MAL      \n 6 2.61e-43       2.05 0.235 0.048  3.58e-39 0       FHIT     \n 7 3.45e-42       1.37 0.488 0.196  4.74e-38 0       PIK3IP1  \n 8 1.41e-40       1.05 0.677 0.373  1.93e-36 0       NOSIP    \n 9 1.51e-37       1.20 0.448 0.184  2.08e-33 0       TCF7     \n10 1.83e-35       1.57 0.244 0.063  2.51e-31 0       TRABD2A  \n# ℹ 2,820 more rows\n\n\nAnother lazy tip: If you are interested in assessing a preliminary result, you could combine the parallelization strategy with the parameter max.cells.per.ident from FindAllMarkers. It will downsample each cluster/ident based on the selected threshold.\n\npbmc_markers &lt;- FindAllMarkers(\n  pbmc_seurat, \n  max.cells.per.ident = 100, # for real datasets you should considered 1000 cells\n  only.pos = TRUE)\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-28/index.html#loading-requirements",
    "href": "posts/2024-03-28/index.html#loading-requirements",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "library(Seurat)\nlibrary(dplyr)\nlibrary(future)\n\nPlease note that we need to establish what parallelization strategy (plan) will be used in our analysis. Also, we are running multiple processes in parallel which can dramatically increase the memory consumption. Be thoughtful about it.\n\n# Setting memory limit for 8Gb\noptions(future.globals.maxSize = 8000 * 1024^2)\n\n# Enabling parallelization\nplan(\"multicore\", workers = 4) # To the date, RStudio does not support parallelization. Run this script using Rscript command-line application.\n\nNext, we will load the PBMC dataset from 10X Genomics. Available here\n\npbmc_seurat &lt;- readRDS(file = \"path/to/pbmc_seurat.RDS\")\npbmc_seurat\n\n\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data"
  },
  {
    "objectID": "posts/2024-03-28/index.html#normalization-and-dimensionality-reduction",
    "href": "posts/2024-03-28/index.html#normalization-and-dimensionality-reduction",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "pbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\npbmc_seurat &lt;- RunPCA(pbmc_seurat)"
  },
  {
    "objectID": "posts/2024-03-28/index.html#clustering",
    "href": "posts/2024-03-28/index.html#clustering",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "As mentioned, often a bioinformatician will evaluate with multiple clustering resolutions. In this tutorial, we will do such a task considering eight different thresholds.\n\npbmc_seurat &lt;- FindNeighbors(pbmc_seurat, dims = 1:10)\npbmc_seurat &lt;- FindClusters(pbmc_seurat, \n                            resolution = c(0.1, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0))"
  },
  {
    "objectID": "posts/2024-03-28/index.html#differential-expression",
    "href": "posts/2024-03-28/index.html#differential-expression",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "Finally, we will execute the differential expression analysis.\n\npbmc_markers &lt;- FindAllMarkers(pbmc_seurat, only.pos = TRUE)\n\n\npbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    dplyr::filter(avg_log2FC &gt; 1)\n\n# A tibble: 2,830 × 7\n# Groups:   cluster [11]\n      p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 4.62e-91       1.08 0.954 0.609  6.33e-87 0       LDHB     \n 2 1.94e-89       2.11 0.517 0.124  2.66e-85 0       CCR7     \n 3 1.68e-52       1.76 0.396 0.117  2.30e-48 0       PRKCQ-AS1\n 4 9.77e-52       1.83 0.388 0.114  1.34e-47 0       LEF1     \n 5 1.77e-43       1.89 0.323 0.09   2.42e-39 0       MAL      \n 6 2.61e-43       2.05 0.235 0.048  3.58e-39 0       FHIT     \n 7 3.45e-42       1.37 0.488 0.196  4.74e-38 0       PIK3IP1  \n 8 1.41e-40       1.05 0.677 0.373  1.93e-36 0       NOSIP    \n 9 1.51e-37       1.20 0.448 0.184  2.08e-33 0       TCF7     \n10 1.83e-35       1.57 0.244 0.063  2.51e-31 0       TRABD2A  \n# ℹ 2,820 more rows\n\n\nAnother lazy tip: If you are interested in assessing a preliminary result, you could combine the parallelization strategy with the parameter max.cells.per.ident from FindAllMarkers. It will downsample each cluster/ident based on the selected threshold.\n\npbmc_markers &lt;- FindAllMarkers(\n  pbmc_seurat, \n  max.cells.per.ident = 100, # for real datasets you should considered 1000 cells\n  only.pos = TRUE)\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-05-28/index.html",
    "href": "posts/2024-05-28/index.html",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "",
    "text": "Korsunsky et al. (2019)\nNot long ago, we discussed ways to speed up differential expression analysis in single-cell datasets.\nFor that, I wrote a quick snippet using the future package for parallelizing. This is 100% cool. But, recently I found a more convenient way to do such a task. On this note, since an old dog can still learn new tricks, I would like to introduce: presto.\nPresto is a Wilcoxon rank sum test and auROC implementation that can run 1 million observations, 1K features, and 10 groups in 16 seconds (sparse input) and 85 seconds (dense input) 1. Yes, sir, we are fast.\nHowever, presto isn’t a very new tool! It has been around for at least 5 years (based on GitHub development). Yet, it became much more convenient once it was integrated into the Seurat package (version 5.1.0) 2.\nLet’s do a quick and dirty hands-on.\nFirst, we need to load the package and the data we will use for this example. I will use the same data that I used in this debugging new post."
  },
  {
    "objectID": "posts/2024-05-28/index.html#loading-requirements",
    "href": "posts/2024-05-28/index.html#loading-requirements",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "1. Loading requirements",
    "text": "1. Loading requirements\n\nlibrary(Seurat)\nlibrary(dplyr)\nlibrary(presto) # Optional. It will be loaded behind the scenes."
  },
  {
    "objectID": "posts/2024-05-28/index.html#loading-pre-processed-seurat-object",
    "href": "posts/2024-05-28/index.html#loading-pre-processed-seurat-object",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "2. Loading pre-processed Seurat object",
    "text": "2. Loading pre-processed Seurat object\n\nseurat_object &lt;- readRDS(file = here::here(\"./data/Ovarian_main_cluster_object.20k.RDS\"))"
  },
  {
    "objectID": "posts/2024-05-28/index.html#running-deg-analysis-across-clusters",
    "href": "posts/2024-05-28/index.html#running-deg-analysis-across-clusters",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "3. Running DEG analysis across clusters",
    "text": "3. Running DEG analysis across clusters\n\nstart_time &lt;- Sys.time()\n\n# Find markers for every cluster compared to all remaining cells, report only the positive\nseurat_markers &lt;- FindAllMarkers(seurat_object, only.pos = TRUE)\n\nend_time &lt;- Sys.time()\n\nWhat?! How is that? I haven’t change my code at all.\nYes, young bioinformatician. I said it was convenient everything you need for running it is already in place in Seurat version 5.1.0. For those not using this versions, you can also rely on SeuratWrappers. This package has a function called RunPrestoAll."
  },
  {
    "objectID": "posts/2024-05-28/index.html#inspecting-deg-table",
    "href": "posts/2024-05-28/index.html#inspecting-deg-table",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "4. Inspecting DEG table",
    "text": "4. Inspecting DEG table\n\nseurat_markers %&gt;%\n  group_by(cluster) %&gt;%\n  select(cluster, gene, pct.1, pct.2, avg_log2FC, p_val) %&gt;%\n  top_n(5)\n\n# A tibble: 110 × 6\n# Groups:   cluster [22]\n   cluster gene            pct.1 pct.2 avg_log2FC   p_val\n   &lt;fct&gt;   &lt;chr&gt;           &lt;dbl&gt; &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;\n 1 0       SLC26A1         0.01  0.004      0.798 0.00631\n 2 0       NATD1           0.037 0.024      0.246 0.00740\n 3 0       SLC35G1         0.012 0.005      0.428 0.00770\n 4 0       ENSG00000273088 0.022 0.012      0.145 0.00832\n 5 0       CTSK            0.041 0.027      0.903 0.00873\n 6 1       TMSB15B.1       0.012 0.006      2.82  0.00975\n 7 1       PGLYRP2         0.018 0.01       1.93  0.00975\n 8 1       ZNF585B         0.016 0.031      0.418 0.00977\n 9 1       ZNF567          0.078 0.111      0.785 0.00983\n10 1       SOBP            0.011 0.023      0.128 0.00988\n# ℹ 100 more rows\n\n\nPretty cool, right? Identical results, but much faster."
  },
  {
    "objectID": "posts/2024-05-28/index.html#measuring-computational-time",
    "href": "posts/2024-05-28/index.html#measuring-computational-time",
    "title": "Yet another tip for speeding up DEG analysis on Seurat",
    "section": "5. Measuring computational time",
    "text": "5. Measuring computational time\n\ncomputational_time &lt;- round(end_time - start_time, 2)\n\n\n\n\n\n\n\nTip\n\n\n\nYeah, we ran the FindAllMarkers function into 39.65 seconds. The authors claimed that it could be 295 times faster than conventional implementations. Do not trust them? Feel free to run it. Hint: You might need to change your Seurat version. Also, you can use the toy dataset in this tutorial, it can be found here.\n\n\n\n\n\nKorsunsky et al. (2019)"
  },
  {
    "objectID": "posts/2024-04-09/index.html",
    "href": "posts/2024-04-09/index.html",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "",
    "text": "Suppose that we have a set of differentially expressed genes (DEG) from RNA-Seq data and their corresponding log2FoldChanges. Let’s create a protein-protein interaction (PPI) network with StringDB using some R packages. By combining PPI information and gene expression, we can have insights about how the DEGs can impact (or be impacted by) other genes.\nYou can download the data from this tutorial here."
  },
  {
    "objectID": "posts/2024-04-09/index.html#step-1-retrieve-the-ppi-network-from-stringdb",
    "href": "posts/2024-04-09/index.html#step-1-retrieve-the-ppi-network-from-stringdb",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "Step 1: Retrieve the PPI network from StringDB",
    "text": "Step 1: Retrieve the PPI network from StringDB\nBefore starting, you’ll need to install and load the following packages:\n\nlibrary(RedeR)\nlibrary(igraph)\n\nLet’s import the table with the DEGs. In this table there is a column for gene symbols and another column for their corresponding log2FoldChanges.\n\ndegs &lt;- read.csv(\"exp-table.csv\")\nhead(degs)\n\n   genes     log2fc\n1   ACLY  0.6864199\n2   ACO1 -1.4629591\n3   ACO2 -3.7851444\n4     CS  2.0569852\n5 DHTKD1  3.0715545\n6   DLAT  1.8612732\n\n\nWe’re using the stringDB API to retrieve PPI information (for more information of each API’s methods, visit https://string-db.org/help/api/).\nThe first method to be used is the get_string_ids, which will map a list of genes to the stringDB’s identifiers (https://string-db.org/cgi/help.pl?subpage=api%23mapping-identifiers.\nWhen submitting a request to the stringDB API programmatically, we need to concatenate the identifiers by the symbol “%0d” (this is the standard separator for gene names).\n\ngenes &lt;- paste0(degs$genes, collapse = \"%0d\")\n\nNow we can make a request with the postForm function from the RCurl package. An important parameter is the species, which stands for the NCBI taxonomy ID for the genes/proteins we’re considering. In this case, we are dealing with human genes (taxid: 9606).\n\nreq &lt;- RCurl::postForm(\n  \"https://string-db.org/api/tsv/get_string_ids\",\n  identifiers = genes, # gene names\n  echo_query = \"1\",\n  species = \"9606\" # homo sapiens taxid\n)\nids_mapped &lt;- read.table(text = req, sep = \"\\t\", header = T, quote = \"\")\n\nhead(ids_mapped[,1:3])\n\n  queryItem queryIndex             stringId\n1      ACLY          0 9606.ENSP00000466259\n2      ACO1          1 9606.ENSP00000309477\n3      ACO2          2 9606.ENSP00000216254\n4        CS          3 9606.ENSP00000342056\n5    DHTKD1          4 9606.ENSP00000263035\n6      DLAT          5 9606.ENSP00000280346\n\n\nWe mapped each gene name to their corresponding proteins annotated on the StringDB (the stringId column). Now, let’s use these StringIDs to retrieve the interaction information:\n\nstringids &lt;- paste0(unique(ids_mapped$stringId), collapse = \"%0d\")\n\nreq &lt;- RCurl::postForm(\n  \"https://string-db.org/api/tsv/network\",\n  identifiers = stringids, # stringids \n  required_core = \"0\", # minimal score\n  species     = \"9606\"  # homo sapiens taxid\n)\n\nppi &lt;- read.table(text = req, sep = \"\\t\", header = T)\nhead(ppi[,1:2])\n\n            stringId_A           stringId_B\n1 9606.ENSP00000216254 9606.ENSP00000258886\n2 9606.ENSP00000216254 9606.ENSP00000223366\n3 9606.ENSP00000216254 9606.ENSP00000297283\n4 9606.ENSP00000216254 9606.ENSP00000295266\n5 9606.ENSP00000216254 9606.ENSP00000290573\n6 9606.ENSP00000216254 9606.ENSP00000264663\n\n\nThe dataframe represents a network format called edge list. It represents the interaction between the proteins on the stringId_A column and the proteins on the stringId_B column. For example, the protein 9606.ENSP00000216254 interacts with the protein 9606.ENSP00000258886. The interaction information of a given protein A and a protein B comes from different sources or channels. StringDB returns the following channels:\nscore: combined score\nnscore: gene neighborhood score\nfscore: gene fusion score\npscore: phylogenetic profile score\nascore: coexpression score\nescore: experimental score\ndscore: database score\ntscore: textmining score\nAs you guessed, the combined score represents the score combination of all other channels. We then can select the interactions based on a combined score of 0.7 (you can choose other channels as a reference for the interactions):\n\nppi &lt;- subset(ppi, ppi$score &gt;= 0.7)\nnrow(ppi)\n\n[1] 375\n\n\nThis leaves us with 375 interactions reported for the proteins retrieved from our initial DEGs list."
  },
  {
    "objectID": "posts/2024-04-09/index.html#step-2-plot-the-ppi-network-with-reder",
    "href": "posts/2024-04-09/index.html#step-2-plot-the-ppi-network-with-reder",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "Step 2: Plot the PPI network with RedeR",
    "text": "Step 2: Plot the PPI network with RedeR\nRedeR is an R/Bioconductor package suitable to plot and manipulate networks. It presents a friendly interface to facilitate network customization (See the vignette for the complete guideline).\nFirst, let’s create a dataframe holding the information regarding each gene, their associated protein, and the log2FC:\n\nannotation &lt;- merge(degs,\n                    ids_mapped[, c(\"queryItem\", \"stringId\")],\n                    by.x = \"genes\", \n                    by.y = \"queryItem\")\nhead(annotation)\n\n   genes     log2fc             stringId\n1   ACLY  0.6864199 9606.ENSP00000466259\n2   ACO1 -1.4629591 9606.ENSP00000309477\n3   ACO2 -3.7851444 9606.ENSP00000216254\n4     CS  2.0569852 9606.ENSP00000342056\n5 DHTKD1  3.0715545 9606.ENSP00000263035\n6   DLAT  1.8612732 9606.ENSP00000280346\n\n\nNow, let’s use the igraph package to create the network. igraph is a multilanguage API created to represent data as networks. If you want to know more about the igraph R interface, see their vignette: https://r.igraph.org/. Here, we used the directed = FALSE argument because PPI networks are undirected networks.\n\ngraph &lt;- igraph::graph_from_data_frame(ppi[, c(\"stringId_A\", \"stringId_B\")], directed = FALSE)\nplot(graph)\n\n\n\n\n\n\n\n\nThis is not great, the aesthetics can be improved. Now, let’s associate the annotation data.frame we constructed before with the igraph object we created:\n\ngraph &lt;- RedeR::att.mapv(graph, dat = annotation, refcol = 3)\n\nThe att.mapv function associates node information from the annotation dataframe to the graph. The refcol argument specifies which column on the annotation dataframe corresponds to the node ID used to build the graph (in this case, we used the stringID, the third column on the annotation dataframe). This is the reference column that will be used to set other attributes to our network.\nUsually, it is more informative to represent the nodes as gene names. Let’s also color the nodes following the log2FC scale. To do that, let’s set those attributes on the graph we created with the att.setv function:\n\ngraph &lt;- RedeR::att.setv(graph, from = \"genes\", to = \"nodeAlias\")\ngraph &lt;- RedeR::att.setv(graph, from = \"log2fc\", to = \"nodeColor\", breaks = seq(-2, 2, 0.4), pal = 2)\n\nNow, we launch the RedeR interface and we add the network to it:\n\n# Launch RedeR\nrdp &lt;- RedPort()\ncalld(rdp)\n\n# Add graph to RedeR interface\naddGraph(rdp, graph)\n\nFrom there, you can play around with your network and display the nodes as you wish by clicking and dragging them. Or you can hit the “Start relax” button and the RedeR will look for an optimal layout for your network. This is specially useful for big networks. You can test different force parameters and see how it affects your network layout.\n\nAt last, let’s add a legend for color scale:\n\nscl &lt;- graph$legNodeColor$scale\nleg &lt;- graph$legNodeColor$legend \naddLegend.color(rdp, \n                colvec = scl, \n                labvec = leg, \n                title = \"log2FC\")\n\n\nAnd voilà! You can save the network image by clicking in “File” &gt; “Export” &gt; “Image” and chosing the desired format."
  },
  {
    "objectID": "posts/2024-05-07/index.html",
    "href": "posts/2024-05-07/index.html",
    "title": "scGPT: A foundation model for single-cell genomics that got it! (The Right Stuff).",
    "section": "",
    "text": "From (Cui et al. 2024)\n\n\nGenerative pre-trained models are the new cool kid on the block 😎 that no one can ignore anymore. Usage of this new approach have tremendous impact in a broad amount of areas. Biology is no exception, with complex molecular signatures, different cell types, states, and all kinds of different experiments to induce alteration in specific mechanisms make this a perfect storm to get more meaningful information from this source.\nIn a single approach, scGPT has managed to get 6 different important aspects from scRNAseq: 1) Clustering; 2) Batch Correction; 3) Cell type annotation; 4) Gene network inference; 5) Multiomic integration; and 6) Perturbation prediction;\nFor this first version of scGPT, it was used 33 million cells from CELLxGENE collection with 51 organs / tissues and 441 different studies, which represented a most of cellular differences across human body.\nAuthors have reported that their model without any fine-tuning can achieve impressive &gt;80% precision while annotating non-rare cell types, and with some fine-tuning this precision can reach ~85%. Looking at perturbation, removal of 1 or 2 genes, in a cell model, fine-tuned scGPT was able to reach 60% of Pearson correlation, outcoming previous models by 5-20%. Integration of datasets also outperformed known techniques from scVI, Seurat and Harmony by 5-10%. GRN-inference was also tested finding not just known networks in curated datasets but also being able to predict interference in those networks.\nAlthough too good to be true, we definitely can´t take our eyes out from start using more and more this type of approach as Satija (Seurat main coordinator) have highlighted in his last Single Cell Genomics Day.\nConclusion is that we are reaching a point that most of manual / semi-automated work running pipelines to describe cell types + extracting meaningful information scRNAseq would be mostly done by one of those generative models. In a near future, we might ask an LLM (as GPT4) with our fastqs which cell types and meaningful biological information can be found in our scRNAseq experiments.\nAuthors were also very generous to provide lots of examples in jupyter notebooks in their github repo scGPT. What you think about we explore this here in our blog for a next post? - Provide us some feedback in our Linkedin post!\n\n\n\nFrom (Cui et al. 2024)\n\n\n\nReferences\n\nCui, Haotian, Chloe Wang, Hassaan Maan, Kuan Pang, Fengning Luo, Nan Duan, and Bo Wang. 2024. “scGPT: Toward Building a Foundation Model for Single-Cell Multi-Omics Using Generative AI.” Nature Methods 2024, February, 1–11. https://doi.org/10.1038/s41592-024-02201-0."
  },
  {
    "objectID": "posts/2024-04-04/index.html",
    "href": "posts/2024-04-04/index.html",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "",
    "text": "Basic taxonomic classification of long and short reads with Kraken2\nThe taxonomic classification of reads from sequencing experiments has become a common task for most computational biology and bioinformatics projects. To facilitate this process, Kraken2 was developed to make it faster and computationally less costly (Wood, Lu, and Langmead 2019).\nTo assist those who are new to taxonomic classification activities and even metagenomics, we will describe a brief tutorial here for performing an analysis with Kraken2. It’s worth noting that all commands shown here are extensively described in the software’s manual."
  },
  {
    "objectID": "posts/2024-04-04/index.html#building-the-kraken2-database",
    "href": "posts/2024-04-04/index.html#building-the-kraken2-database",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "1. Building the Kraken2 database",
    "text": "1. Building the Kraken2 database\nThe default Kraken2 database can be easily constructed by executing the following command:\n\nkraken2-build --standard --db kraken_standard\n\nYou can speed up some steps by setting the number of threads to use:\n\n# using 30 threads\nkraken2-build --standard --threads 30 --db kraken_standard\n\nThis process will create a directory named “kraken_standard” containing three files: hash.k2d; opts.k2d and taxo.k2d.\nThe Kraken2 standard database is composed by archaea, bacteria, plasmid, viral, UniVec_Core and human databases from GenBank, and should me enough to a basic metagenomics analysis.\n\nNote: Building the standard database will require approximately 500 GB of free space on the hard drive (due to intermediate files) and 80 GB RAM, based on the data downloaded at the time of this publication.\n\n\nTip: rsync connection may crash sometimes. In this case, just run the command again, and Kraken2 will return to the point where the last complete library left off."
  },
  {
    "objectID": "posts/2024-04-04/index.html#classification",
    "href": "posts/2024-04-04/index.html#classification",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "2. Classification",
    "text": "2. Classification\nAfter an extensive database-building job, the time to classify your reads has come. Here I will use the “kraken_standard” created in the last command. You shall change this parameter to the given database that you might be creating.\n\nkraken2 \\\n  --db kraken_standard \\\n  --output kraken_out.txt \\\n  --report kraken_report.txt \\\n  --threads 10 \\\n  gut_unmapped.fastq.gz\n\n--output: Will write the taxonomic classification of each read into the kraken_out.txt file\n--report: Will write the the number of minimizers in the database that are mapped to the various taxa/clades into the kraken_report.txt file. Write this file will be useful for further analysis with Braken, Taxpasta and Krona.\ngut_unmapped.fastq.gz: Are my reads dataset that I want to classify. You may change this parameter to the path and name of the file that you are going to classify."
  },
  {
    "objectID": "posts/2024-04-18/index.html",
    "href": "posts/2024-04-18/index.html",
    "title": "How much does it cost a Bioinformatician? - Asking ChatGPT",
    "section": "",
    "text": "Some time ago, I became curious about the gross salary range for bioinformaticians across various countries in Europe and North America. While browsing through platforms like Glassdoor and Indeed seemed exhaustive, I opted to try ChatGPT for insights. After obtaining data from ChatGPT, I chose to convert the yearly gross salary into a month rate, considering a standard work year of 12 months. After this was just some plotting with ggplot2. These are the results I discovered.\n\n\n\nFig 1. Average Bioinformatician salaries among countries in Europe / North America normalized (USD/month). Salary lines are divided in max (green), average (red) and min (blue). I have also included a yellow dashed line to indicate overall average.\n\n\nChatGPT have found an overall average of ~4250 USD/ month (Annualy: 51000 USD or 26 USD/h). This does not take into account bonuses and benefits.\nAlso asked same for software developer, post doctoral position and data analyst.\n\n\n\nFig 2. Average Post Doctoral salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\n\n\n\nFig 3. Average Software Developer salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\n\n\n\nFig 4. Average Data Analyst salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\nThose plots might not be a full picture but give us a hint of how Bioinformatics is doing in IT world.\nIf you are also interested in how I did this plot, you can find it below:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nplot_salary &lt;- function(data_file, prof){\n    tab = read.csv(data_file, header = T)\n    tab = tab %&gt;% pivot_longer(names_to = \"Salary\", values_to = \"value\", cols = 3:5)\n    img = tab %&gt;% \n        ggplot(aes(x = reorder(Country, value), y = value / 12)) + \n        geom_point() +\n        geom_smooth(aes(x = as.numeric(as.factor(reorder(Country, value))), color = Salary), se = F) +\n        geom_hline(yintercept = mean(tab$value) / 12, colour = \"orange\", linetype = \"longdash\") +\n        ylim(0, 12000) +\n        theme_classic() + labs(y=\"USD / month (Gross Salary)\", x = \"Countries\",\n                                title = prof) +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),\n                axis.title = element_text(size = 20),\n                title = element_text(size = 20),\n                legend.position = \"none\")\n    print(mean(tab$value/12))\n    return(img)\n}\n\n\n\n# This is how table would look like:\n# Country,Title,Min Salary (USD),Avg Salary (USD),Max Salary (USD)\n# United Kingdom,Postdoc,32000,42000,52000\n# Germany,Postdoc,38000,48000,58000\n# France,Postdoc,33000,43000,53000\n# ....\n\nbioinfo_file &lt;- \"../../data/salaries_bioinfo_table.csv\"\npng(filename = \"Bioinfo_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(bioinfo_file, \"Bioinfoinformatician\")\ndev.off()\n\npostdoc_file &lt;- \"../../data/salaries_post_table.csv\"\npng(filename = \"PostDoc_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(postdoc_file, \"Postdoc\")\ndev.off()\n\nsoft_file &lt;- \"../../data/salaries_sd_table.csv\"\npng(filename = \"Soft_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(soft_file, \"Software Developer\")\ndev.off()\n\nsoft_file &lt;- \"../../data/salaries_da_table.csv\"\npng(filename = \"DA_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(soft_file, \"Data Analyst\")\ndev.off()"
  }
]