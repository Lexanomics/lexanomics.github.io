[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Lexanomics Blog",
    "section": "",
    "text": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 18, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nHow much does it cost a Bioinformatician? - Asking ChatGPT\n\n\n\n\n\n\nbioinformatics\n\n\n\n\n\n\n\n\n\nApr 18, 2024\n\n\nDiego M. Coelho\n\n\n\n\n\n\n\n\n\n\n\n\nClinical application of bronchoalveolar lavage fluid metagenomics next-generation sequencing in cancer patients with severe pneumonia\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nApr 11, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nCreating a PPI network from a list of differentially expressed genes\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 9, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nBasic taxonomic classification of long and short reads with Kraken2\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nApr 4, 2024\n\n\nDiego Gomes\n\n\n\n\n\n\n\n\n\n\n\n\nRedefining the treponemal history through pre-Columbian genomes from Brazil\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nApr 2, 2024\n\n\nDiego Gomes\n\n\n\n\n\n\n\n\n\n\n\n\nParallelization tips on Seurat\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMar 28, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nCholesin: a new hormone discovered for controlling cholesterol levels in humans\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 26, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nThe butterfly effect: lncRNAs in the evolutionists‚Äô sights\n\n\n\n\n\n\nawesome science\n\n\nevolution\n\n\nlncRNA\n\n\n\n\n\n\n\n\n\nMar 19, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nData interoperability for single-cell analysis\n\n\n\n\n\n\ndebbuging new\n\n\n\n\n\n\n\n\n\nMar 14, 2024\n\n\nLexanomics\n\n\n\n\n\n\n\n\n\n\n\n\nUnveiling the Beginning of the Pandemic: The Transformative Role of Meta-Transcriptomics in Pathogen Identification\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 12, 2024\n\n\nDiego Teixeira\n\n\n\n\n\n\n\n\n\n\n\n\nWhy to sequence the DNA?\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nMar 8, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nJumping genetic element getting in the way of primates tail evolution\n\n\n\n\n\n\nawesome science\n\n\n\n\n\n\n\n\n\nMar 3, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nAnalysing the cell transcriptional profile at the single-cell resolution\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 29, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nA new look into microorganisms by the lens of metagenomics\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 28, 2024\n\n\nIara Souza\n\n\n\n\n\n\n\n\n\n\n\n\nAre you aware about RNA sequencing analysis?\n\n\n\n\n\n\nbioinfo-trends\n\n\nsequencing-technologies\n\n\n\n\n\n\n\n\n\nFeb 27, 2024\n\n\nIara Souza\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-03-12/index.html",
    "href": "posts/2024-03-12/index.html",
    "title": "Unveiling the Beginning of the Pandemic: The Transformative Role of Meta-Transcriptomics in Pathogen Identification",
    "section": "",
    "text": "The year 2020 will forever be remembered as the starting point of the COVID-19 pandemic, declared by the World Health Organization. A revolution in the speed of information generation marked this period, especially concerning the characterization of SARS-CoV-2 and the understanding of COVID-19.\n\n\n\nDesigned by Freepik\n\n\nIn just 12 days, from the hospital admission of a patient with characteristic COVID-19 symptoms to the publication in the prestigious journal Nature, the process of characterizing SARS-CoV-2 was remarkably efficient. In the study titled A New Coronavirus Associated with Human Respiratory Disease in China by Wu and collaborators (Wu et al. 2020), an advanced analytical method took center stage: meta-transcriptomics.\nTo better comprehend the pathogen infecting the patient, researchers employed high-coverage meta-transcriptomic sequencing through the Illumina MiniSeq platform. The biological sample from bronchoalveolar lavage fluid underwent de novo contig assembly, revealing a 30,474-nucleotide sequence closely related to the SARS-like coronavirus genome found in bats (CoV) and recorded in the GenBank.\nThe identified virus was named WH-Human 1 coronavirus (WHCV). Analysis of the viral sequence not only allowed for the inference of the transmission route but also uncovered mutations in the receptor-binding domain (RBD) of the SPIKE protein. This mutation was crucial, enabling the viral lineage to bind to the ACE2 protein and thus infect human cells. Additionally, the research traced the evolutionary events that gave rise to the virus later known as SARS-CoV-2.\nThis study stands as a remarkable example of how contemporary sequencing techniques, combined with careful analysis of biological data tools, play a vital role in the early detection of pathogens and the timely identification of agents capable of triggering local or global outbreaks.\nStay updated on metatranscriptomics, metagenomics, NGS, pathogens, virus, and COVID-19, and discover how science is unveiling the secrets behind global health threats.\n\n\n\n\nReferences\n\nWu, F., S. Zhao, B. Yu, and et al. 2020. ‚ÄúA New Coronavirus Associated with Human Respiratory Disease in China.‚Äù Nature 579: 265‚Äì69. https://doi.org/10.1038/s41586-020-2008-3."
  },
  {
    "objectID": "posts/2024-04-18/index.html",
    "href": "posts/2024-04-18/index.html",
    "title": "How much does it cost a Bioinformatician? - Asking ChatGPT",
    "section": "",
    "text": "Some time ago, I became curious about the gross salary range for bioinformaticians across various countries in Europe and North America. While browsing through platforms like Glassdoor and Indeed seemed exhaustive, I opted to try ChatGPT for insights. After obtaining data from ChatGPT, I chose to convert the yearly gross salary into a month rate, considering a standard work year of 12 months. After this was just some plotting with ggplot2. These are the results I discovered.\n\n\n\nFig 1. Average Bioinformatician salaries among countries in Europe / North America normalized (USD/month). Salary lines are divided in max (green), average (red) and min (blue). I have also included a yellow dashed line to indicate overall average.\n\n\nChatGPT have found an overall average of ~4250 USD/ month (Annualy: 51000 USD or 26 USD/h). This does not take into account bonuses and benefits.\nAlso asked same for software developer, post doctoral position and data analyst.\n\n\n\nFig 2. Average Post Doctoral salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\n\n\n\nFig 3. Average Software Developer salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\n\n\n\nFig 4. Average Data Analyst salaries among countries in Europe / North America normalized (USD/month). Same as fig 1.\n\n\nThose plots might not be a full picture but give us a hint of how Bioinformatics is doing in IT world.\nIf you are also interested in how I did this plot, you can find it below:\n\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(tidyr)\n\nplot_salary &lt;- function(data_file, prof){\n    tab = read.csv(data_file, header = T)\n    tab = tab %&gt;% pivot_longer(names_to = \"Salary\", values_to = \"value\", cols = 3:5)\n    img = tab %&gt;% \n        ggplot(aes(x = reorder(Country, value), y = value / 12)) + \n        geom_point() +\n        geom_smooth(aes(x = as.numeric(as.factor(reorder(Country, value))), color = Salary), se = F) +\n        geom_hline(yintercept = mean(tab$value) / 12, colour = \"orange\", linetype = \"longdash\") +\n        ylim(0, 12000) +\n        theme_classic() + labs(y=\"USD / month (Gross Salary)\", x = \"Countries\",\n                                title = prof) +\n        theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 12),\n                axis.title = element_text(size = 20),\n                title = element_text(size = 20),\n                legend.position = \"none\")\n    print(mean(tab$value/12))\n    return(img)\n}\n\n\n\n# This is how table would look like:\n# Country,Title,Min Salary (USD),Avg Salary (USD),Max Salary (USD)\n# United Kingdom,Postdoc,32000,42000,52000\n# Germany,Postdoc,38000,48000,58000\n# France,Postdoc,33000,43000,53000\n# ....\n\nbioinfo_file &lt;- \"../../data/salaries_bioinfo_table.csv\"\npng(filename = \"Bioinfo_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(bioinfo_file, \"Bioinfoinformatician\")\ndev.off()\n\npostdoc_file &lt;- \"../../data/salaries_post_table.csv\"\npng(filename = \"PostDoc_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(postdoc_file, \"Postdoc\")\ndev.off()\n\nsoft_file &lt;- \"../../data/salaries_sd_table.csv\"\npng(filename = \"Soft_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(soft_file, \"Software Developer\")\ndev.off()\n\nsoft_file &lt;- \"../../data/salaries_da_table.csv\"\npng(filename = \"DA_USD_h.png\", res = 300, width = 3000, height = 2000)\nplot_salary(soft_file, \"Data Analyst\")\ndev.off()"
  },
  {
    "objectID": "posts/2024-03-14/index.html",
    "href": "posts/2024-03-14/index.html",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Seurat is undoubtedly the most used package for single-cell analysis. However, the single-cell field has changed towards new programming languages and packages (e.g., Scanpy), which leads to an issue regarding interoperability , i.e., the ability of software to exchange and make use of information. Here, we show how to quickly convert Seurat objects from ongoing projects to AnnData (Scanpy data object).\n\n\n\n\n\n\n\n\nlibrary(Seurat)\nlibrary(dplyr)\nlibrary(sceasy)\n\n# Setting Assay version 5\noptions(Seurat.object.assay.version = \"v5\")\n\n# Load the PBMC dataset - available at 10x datasets website\npbmc.data &lt;- Read10X(\n    data.dir = \"/Users/affaustino/Projects/UTILS/quarto_blog/data/filtered_gene_bc_matrices/hg19\")\n\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc_seurat &lt;- CreateSeuratObject(\n  counts = pbmc.data, project = \"pbmc3k\", min.cells = 3, min.features = 200)\n\n\n# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\npbmc_seurat[[\"percent_mt\"]] &lt;- PercentageFeatureSet(pbmc_seurat, pattern = \"^MT-\")\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\n\n\nOnce we have the Seurat object, we can quickly inspect its structure. Why should we do it? For education, it is nice to understand what slots will be kept over the conversion process.\n\npbmc_seurat\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\npbmc_seurat@assays\n\n$RNA\nAssay (v5) data with 13714 features for 2700 cells\nTop 10 variable features:\n ISG15, CPSF3L, MRPL20, ATAD3C, C1orf86, RER1, RP3-395M20.9, LRRC47,\nGPR153, TNFRSF25 \nLayers:\n counts, data, scale.data \n\n\n\n\n\nIn our experience, the SingleCellExperiment object works as an intermediate layer between Seurat and AnnData. In short, it will ensure that most of the data is maintained among formats.\n\npbmc_sce &lt;- as.SingleCellExperiment(\n    pbmc_seurat)\n\n\n\n\nFinally, we will use sceasy for converting SingleCellExperiment to Anndata. sceasy is a package that helps easily convert different single-cell data formats to each other. Converting to AnnData creates a file that can be directly used in cellxgene which is an interactive explorer for single-cell transcriptomics datasets.\n\nconvertFormat(pbmc_sce, from=\"sce\", to=\"anndata\",\n                       outFile='/Users/affaustino/Projects/UTILS/quarto_blog/data/pbmc.h5ad')\n\nAnnData object with n_obs √ó n_vars = 2700 √ó 13714\n    obs: 'nCount_RNA', 'nFeature_RNA', 'percent_mt'\n    var: 'name'\n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-14/index.html#loading-requirements",
    "href": "posts/2024-03-14/index.html#loading-requirements",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "library(Seurat)\nlibrary(dplyr)\nlibrary(sceasy)\n\n# Setting Assay version 5\noptions(Seurat.object.assay.version = \"v5\")\n\n# Load the PBMC dataset - available at 10x datasets website\npbmc.data &lt;- Read10X(\n    data.dir = \"/Users/affaustino/Projects/UTILS/quarto_blog/data/filtered_gene_bc_matrices/hg19\")\n\n# Initialize the Seurat object with the raw (non-normalized data).\npbmc_seurat &lt;- CreateSeuratObject(\n  counts = pbmc.data, project = \"pbmc3k\", min.cells = 3, min.features = 200)\n\n\n# The [[ operator can add columns to object metadata. This is a great place to stash QC stats\npbmc_seurat[[\"percent_mt\"]] &lt;- PercentageFeatureSet(pbmc_seurat, pattern = \"^MT-\")\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()"
  },
  {
    "objectID": "posts/2024-03-14/index.html#inspecting-object",
    "href": "posts/2024-03-14/index.html#inspecting-object",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Once we have the Seurat object, we can quickly inspect its structure. Why should we do it? For education, it is nice to understand what slots will be kept over the conversion process.\n\npbmc_seurat\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\npbmc_seurat@assays\n\n$RNA\nAssay (v5) data with 13714 features for 2700 cells\nTop 10 variable features:\n ISG15, CPSF3L, MRPL20, ATAD3C, C1orf86, RER1, RP3-395M20.9, LRRC47,\nGPR153, TNFRSF25 \nLayers:\n counts, data, scale.data"
  },
  {
    "objectID": "posts/2024-03-14/index.html#converting-to-singlecellexperiment",
    "href": "posts/2024-03-14/index.html#converting-to-singlecellexperiment",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "In our experience, the SingleCellExperiment object works as an intermediate layer between Seurat and AnnData. In short, it will ensure that most of the data is maintained among formats.\n\npbmc_sce &lt;- as.SingleCellExperiment(\n    pbmc_seurat)"
  },
  {
    "objectID": "posts/2024-03-14/index.html#saving-as-anndata",
    "href": "posts/2024-03-14/index.html#saving-as-anndata",
    "title": "Data interoperability for single-cell analysis",
    "section": "",
    "text": "Finally, we will use sceasy for converting SingleCellExperiment to Anndata. sceasy is a package that helps easily convert different single-cell data formats to each other. Converting to AnnData creates a file that can be directly used in cellxgene which is an interactive explorer for single-cell transcriptomics datasets.\n\nconvertFormat(pbmc_sce, from=\"sce\", to=\"anndata\",\n                       outFile='/Users/affaustino/Projects/UTILS/quarto_blog/data/pbmc.h5ad')\n\nAnnData object with n_obs √ó n_vars = 2700 √ó 13714\n    obs: 'nCount_RNA', 'nFeature_RNA', 'percent_mt'\n    var: 'name'\n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-02-27/index.html",
    "href": "posts/2024-02-27/index.html",
    "title": "Are you aware about RNA sequencing analysis?",
    "section": "",
    "text": "Imagem de DC Studio no Freepik\n\n\nSequencing technologies have revolutionized our understanding of human and other organisms‚Äô biology. By having access to the transcriptome, one can have insights about the cellular functional alterations in different metabolic scenarios. From gene expression data, various analyses can be conducted, including:\nüß¨ Differential expression analysis, to compare the expression levels of genes in case-control scenarios, making possible the identification of biomarkers and gene signatures;\nüîç Functional enrichment analysis and gene set enrichment analysis (GSEA), to understand the impact of transcriptional alterations in cellular pathways and metabolic context;\nü§ù Co-expression analysis, to gather gene modules collectively expressed in a given condition;\nüîÑ Protein-protein interaction networks, to understand how gene targets interact with each other in a functional and/or physical way;\nüìä Expression deconvolution, to infer cell type proportions from curated reference panels;\nüîó Construction of regulatory networks, to understand how regulatory elements, such as transcription factors and non-coding RNAs, impact the transcriptional profile of a given condition.\nHere in Lexanomics, we have extensive experience in preprocessing RNA-Seq data by using gold-standard bioinformatics tools and protocols, which can help you to increase the impact of your research. Let‚Äôs advance together! üöÄ #Lexanomics #RNAseq #Bioinformatics #Research"
  },
  {
    "objectID": "posts/2024-04-16/index.html",
    "href": "posts/2024-04-16/index.html",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "There are many reasons why a researcher wants to perform pseudotime analysis on single-cell datasets, including but not limited to cellular differentiation, developmental stages, and disease progression.\nCurrently, we can leverage many packages for dealing with such analysis. We could roughly categorize them into approaches based on user-defined roots and model-based roots. Note that roots are the starting point of the pseudotime analysis, i.e., the algorithm will sort the cells and their transcriptional profiles based on that specific data point. Therefore, it is a VERY crucial step in pseudotime!\nOn that note, Monocle3 is a well-known package for performing pseudotime analysis. It should be included in the ‚Äúuser-defined‚Äù category, i.e., it relies on a knowledge-driven selection. To aid bioinformaticians in root selection, we can leverage distinct models to give us hints. Today, we will talk about CytoTRACE, a package for measuring differentiation scores in single-cell datasets. CytoTRACE is based on the simple observation that transcriptional diversity‚Äîthe number of genes expressed in a cell‚Äîdecreases during differentiation. Thus, we can assume that cells predicted as less differentiated are the best candidates for pseudotime roots. Check it out!\n\n\n\n\n\n\n\n\n\n\n\nlibrary(Seurat)\nlibrary(SeuratWrappers)\nlibrary(monocle3)\nlibrary(UCell)\nlibrary(dbscan)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Loading the CytoTRACE code.\nsource(here::here(\"./data/CytoTRACE.R\"))\nsource(here::here(\"./data/plotCytoTRACE.R\"))\n\n\n\n\nHere, we will leverage data from V√°zquez-Garc√≠a et al (2022). This data was subset for only 20.000 cells, including malignant and TME cells. Particularly, this dataset was CD45+ and CD45‚àí flow-sorted, i.e., we can easily distinguish between putative malignant, epithelial cells and TME-related cells.\n\nseurat_object &lt;- readRDS(file = here::here(\"./data/Ovarian_main_cluster_object.20k.RDS\"))\n\n\nDimPlot(\n  seurat_object,\n  group.by = \"Sort\"\n)\n\n\n\n\n\n\n\n\n\n\n\nNext, we will subset NK cells based on lineage markers. It is fairly easy to do once we know which genes to look at. We will provide a small, but accurate list for major cell types.\n\ncell_lineage_markers &lt;- list(\n  \"T-Cells\" = c(\"CD3D\",\"CD3E\",\"CD4\",\"CD8A\",\"CD8B\"), \n  \"NK_cells\" = c(\"NCAM1\",\"KLRG1\",\"FCGR3A\",\"NKG7\",\"GNLY\",\"CD160\"), \n  \"B/Plasma_cells\" = c(\"CD19\",\"MS4A1\",\"CD79A\",\"CD79B\",\"SDC1\",\"MZB1\",\"XBP1\",\"JCHAIN\"), \n  \"Myeloid\" = c(\"LYZ\",\"S100A8\",\"S100A9\",\"CD68\",\"CD14\",\"C1QB\",\"C1QC\"), \n  \"Endothelial\" = c(\"PECAM1\",\"VWF\",\"ENG\",\"MCAM\"), \n  \"Fibroblast\" = c(\"FAP\",\"PDPN\",\"COL1A2\",\"DCN\",\"COL3A1\",\"COL6A1\"),\n  \"Epithelial\" = c(\"EPCAM\",\"MUC1\",\"ERBB2\",\"KRT8\",\"PGC\",\"GKN2\",\"SLC5A5\",\"FABP1\",\"KRT20\")\n)\n\n\nseurat_object &lt;- AddModuleScore_UCell(\n  seurat_object,\n  ncores = 8,\n  features = cell_lineage_markers) \n\n\nFeaturePlot(\n  seurat_object, \n  reduction = \"umap\", \n  label = TRUE,\n  ncol = 2,\n  features = paste0(\n    names(cell_lineage_markers), \"_UCell\")\n  )\n\n\n\n\n\n\n\n\n\n\n\nAs expected the signature score derived from UCell can help us to annotate the distinct cell populations. The clusters #1, #7, and #15 are associated with NK and T-cells. This tutorial will consider that clusters #7 and #15 are populated by NK cells. Note, that cluster #15 displays both T and NK signatures, a common feature associated with NK/T-cells. However, we will ignore it for today :)\n\nnk_compartiment_object &lt;- subset(\n  seurat_object, subset = seurat_clusters %in% c(7, 15))\n\n\nnk_compartiment_counts &lt;- LayerData(\n    object = nk_compartiment_object, layer = \"counts\")\n\n\ncyto_results &lt;- CytoTRACE(nk_compartiment_counts)\n\n\nplotCytoTRACE(cyto_results)\n\n\n\n\n\n\n\n\n\n\n\nCytoTRACE will rank the cell based on differentiation score, values ranging from 0 (more differentiated) to 1 (less differentiated).\n\n# Extracting UMAP coordinates\nnk_compartiment_embeddings &lt;- Embeddings(\n  nk_compartiment_object[[\"umap\"]]\n)\n\n# Adding UMAP and CytoTRACE score on metadata\nnk_compartiment_object &lt;- AddMetaData(\n  nk_compartiment_object,\n  nk_compartiment_embeddings\n)\n\nnk_compartiment_object@meta.data[['CytoTRACE']] &lt;- \n  cyto_results$CytoTRACE\n\nNext, we will leverage dbscan for selecting highly-dense clusters with CyTRACE scores higher or equal to 0.9.\n\n# Creating a data.frame with embeddings and CytoTrace score\ndata &lt;- nk_compartiment_object@meta.data[, c(\"umap_1\", \"umap_2\", \"CytoTRACE\")]\ndata &lt;- data %&gt;%\n  mutate(\n    filtered = ifelse(CytoTRACE &gt;= 0.9, \"Yes\", \"No\") \n  )\n\n\n# Subsetting only CytoTRACE higher than 0.9 (less differentiated)\nfiltered_data &lt;- data %&gt;%\n  filter(filtered == \"Yes\") %&gt;%\n  select(umap_1, umap_2)\n\n# Choose eps and minPts based on your dataset characteristics\nclustering &lt;- dbscan(filtered_data, eps = 0.5, minPts = 5)\n\n\n# Calculate k-nearest neighbors distance as a proxy for density\ndistances &lt;- kNNdist(filtered_data, k = 5)  # You might want to adjust this based on the density you expect\n\n# Add distances to your data frame\nfiltered_data$local_density = 1 / distances  # Inverse of distance to indicate density\n\n# Determine the candidate/representative for each cluster\ncluster_representatives &lt;- data.frame()\n\nfor (i in unique(clustering$cluster)) {\n  if (i &gt; 0) {  \n    \n    # Only consider non-noise clusters\n    cluster_data &lt;- filtered_data[clustering$cluster == i,]\n    \n    # Select the data point with the maximum local density\n    representative_index &lt;- which.max(cluster_data$local_density)\n    cluster_representatives &lt;- rbind(cluster_representatives, cluster_data[representative_index, ])\n  }\n}\n\nknitr::kable(cluster_representatives)\n\n\n\n\n\n\n\n\n\n\n\numap_1\numap_2\nlocal_density\n\n\n\n\nSPECTRUM-OV-009_S1_CD45P_RIGHT_UPPER_QUADRANT_AATCGACAGACGGTTG-1\n-7.502961\n3.156997\n15.18489\n\n\n\n\n\n\nggplot(data = data, aes(x = umap_1, y = umap_2)) +\n  geom_point(aes(color = filtered), alpha = 0.5) +\n  geom_point(data = cluster_representatives, color = \"black\", size = 5, shape = 17) +\n  scale_color_manual(values = c(\"grey\", \"blue\", \"black\"), labels = c(\"No\", \"Yes\", \"Candidate\")) +\n  labs(title = \"UMAP Plot\", x = \"UMAP 1\", y =\"UMAP 2\", color = \"Has high CytoTRACE score?\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nOkey dokey! Now we have a decent candidate (black triangle) to be used as a root! We can finally focus on pseudotime analysis with Monocle3.\n\n\n\n\nmonocle_object &lt;- as.cell_data_set(nk_compartiment_object)\nmonocle_object &lt;- cluster_cells(monocle_object)\nmonocle_object &lt;- learn_graph(monocle_object)\n\n\n# This will print out an unrooted trajectory\np0 &lt;- plot_cells(\n  monocle_object,\n  cell_size = 2,\n  label_groups_by_cluster = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np0\n\n\n\n\n\n\n\n\n\n\n\n\nmonocle_object &lt;- order_cells(\n  monocle_object, root_cells = row.names(cluster_representatives)) # Voil√†. We can add the cell_id here.\n\n\np1 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"pseudotime\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np2 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"CytoTRACE\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np1 + p2\n\n\n\n\n\n\n\n\nDone! We now have a basic workflow for defining pseudotime roots without manual intervention. The CytoTRACE + Monocle3 idea was originally published here.\n\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin22.4.0 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRblas.dylib \nLAPACK: /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] dplyr_1.1.2                 ggplot2_3.4.2              \n [3] dbscan_1.1-11               UCell_2.6.2                \n [5] monocle3_1.3.4              SingleCellExperiment_1.23.0\n [7] SummarizedExperiment_1.31.1 GenomicRanges_1.53.1       \n [9] GenomeInfoDb_1.37.2         IRanges_2.35.2             \n[11] S4Vectors_0.39.1            MatrixGenerics_1.13.1      \n[13] matrixStats_1.0.0           Biobase_2.61.0             \n[15] BiocGenerics_0.47.0         SeuratWrappers_0.3.19      \n[17] Seurat_4.9.9.9045           SeuratObject_4.9.9.9084    \n[19] sp_2.0-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.21        splines_4.3.0           later_1.3.1            \n  [4] bitops_1.0-7            tibble_3.2.1            R.oo_1.25.0            \n  [7] polyclip_1.10-4         fastDummies_1.7.3       lifecycle_1.0.3        \n [10] rstatix_0.7.2           rprojroot_2.0.3         globals_0.16.2         \n [13] lattice_0.21-8          MASS_7.3-60             backports_1.4.1        \n [16] magrittr_2.0.3          plotly_4.10.2           rmarkdown_2.23         \n [19] yaml_2.3.7              remotes_2.4.2.1         httpuv_1.6.11          \n [22] sctransform_0.3.5       spam_2.9-1              spatstat.sparse_3.0-2  \n [25] reticulate_1.35.0       cowplot_1.1.1           pbapply_1.7-2          \n [28] minqa_1.2.5             RColorBrewer_1.1-3      abind_1.4-5            \n [31] zlibbioc_1.47.0         Rtsne_0.16              purrr_1.0.2            \n [34] R.utils_2.12.2          RCurl_1.98-1.12         GenomeInfoDbData_1.2.10\n [37] ggrepel_0.9.3           irlba_2.3.5.1           listenv_0.9.0          \n [40] spatstat.utils_3.0-3    terra_1.7-39            goftest_1.2-3          \n [43] RSpectra_0.16-1         spatstat.random_3.1-5   fitdistrplus_1.1-11    \n [46] parallelly_1.36.0       ncdf4_1.21              leiden_0.4.3           \n [49] codetools_0.2-19        DelayedArray_0.27.10    tidyselect_1.2.0       \n [52] farver_2.1.1            viridis_0.6.4           lme4_1.1-34            \n [55] spatstat.explore_3.2-1  jsonlite_1.8.7          BiocNeighbors_1.19.0   \n [58] ellipsis_0.3.2          progressr_0.13.0        ggridges_0.5.4         \n [61] survival_3.5-5          tools_4.3.0             ica_1.0-3              \n [64] Rcpp_1.0.11             glue_1.6.2              gridExtra_2.3          \n [67] SparseArray_1.1.11      xfun_0.39               here_1.0.1             \n [70] withr_2.5.0             BiocManager_1.30.21.1   fastmap_1.1.1          \n [73] HiClimR_2.2.1           boot_1.3-28.1           fansi_1.0.4            \n [76] egg_0.4.5               digest_0.6.33           rsvd_1.0.5             \n [79] R6_2.5.1                mime_0.12               colorspace_2.1-0       \n [82] scattermore_1.2         tensor_1.5              spatstat.data_3.0-1    \n [85] R.methodsS3_1.8.2       utf8_1.2.3              tidyr_1.3.0            \n [88] generics_0.1.3          data.table_1.14.8       robustbase_0.99-0      \n [91] httr_1.4.6              htmlwidgets_1.6.2       S4Arrays_1.1.5         \n [94] uwot_0.1.16             pkgconfig_2.0.3         gtable_0.3.3           \n [97] lmtest_0.9-40           XVector_0.41.1          pcaPP_2.0-3            \n[100] htmltools_0.5.5         carData_3.0-5           dotCall64_1.0-2        \n[103] scales_1.2.1            png_0.1-8               knitr_1.43             \n[106] rstudioapi_0.15.0       reshape2_1.4.4          nlme_3.1-162           \n[109] nloptr_2.0.3            proxy_0.4-27            zoo_1.8-12             \n[112] stringr_1.5.0           KernSmooth_2.23-22      parallel_4.3.0         \n[115] miniUI_0.1.1.1          pillar_1.9.0            grid_4.3.0             \n[118] vctrs_0.6.3             RANN_2.6.1              ggpubr_0.6.0           \n[121] promises_1.2.0.1        car_3.1-2               xtable_1.8-4           \n[124] cluster_2.1.4           evaluate_0.21           mvtnorm_1.2-2          \n[127] cli_3.6.1               compiler_4.3.0          rlang_1.1.1            \n[130] crayon_1.5.2            leidenbase_0.1.25       ggsignif_0.6.4         \n[133] future.apply_1.11.0     labeling_0.4.2          plyr_1.8.8             \n[136] stringi_1.7.12          nnls_1.5                viridisLite_0.4.2      \n[139] deldir_1.0-9            BiocParallel_1.35.3     assertthat_0.2.1       \n[142] ccaPP_0.3.3             munsell_0.5.0           lazyeval_0.2.2         \n[145] spatstat.geom_3.2-4     Matrix_1.6-0            RcppHNSW_0.4.1         \n[148] patchwork_1.1.2         future_1.33.0           shiny_1.7.4.1          \n[151] ROCR_1.0-11             broom_1.0.5             igraph_1.5.1           \n[154] DEoptimR_1.1-0         \n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-04-16/index.html#loading-requirements",
    "href": "posts/2024-04-16/index.html#loading-requirements",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "library(Seurat)\nlibrary(SeuratWrappers)\nlibrary(monocle3)\nlibrary(UCell)\nlibrary(dbscan)\nlibrary(ggplot2)\nlibrary(dplyr)\n\n# Loading the CytoTRACE code.\nsource(here::here(\"./data/CytoTRACE.R\"))\nsource(here::here(\"./data/plotCytoTRACE.R\"))"
  },
  {
    "objectID": "posts/2024-04-16/index.html#loading-pre-processed-seurat-object",
    "href": "posts/2024-04-16/index.html#loading-pre-processed-seurat-object",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "Here, we will leverage data from V√°zquez-Garc√≠a et al (2022). This data was subset for only 20.000 cells, including malignant and TME cells. Particularly, this dataset was CD45+ and CD45‚àí flow-sorted, i.e., we can easily distinguish between putative malignant, epithelial cells and TME-related cells.\n\nseurat_object &lt;- readRDS(file = here::here(\"./data/Ovarian_main_cluster_object.20k.RDS\"))\n\n\nDimPlot(\n  seurat_object,\n  group.by = \"Sort\"\n)"
  },
  {
    "objectID": "posts/2024-04-16/index.html#performing-basic-cell-type-annotation",
    "href": "posts/2024-04-16/index.html#performing-basic-cell-type-annotation",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "Next, we will subset NK cells based on lineage markers. It is fairly easy to do once we know which genes to look at. We will provide a small, but accurate list for major cell types.\n\ncell_lineage_markers &lt;- list(\n  \"T-Cells\" = c(\"CD3D\",\"CD3E\",\"CD4\",\"CD8A\",\"CD8B\"), \n  \"NK_cells\" = c(\"NCAM1\",\"KLRG1\",\"FCGR3A\",\"NKG7\",\"GNLY\",\"CD160\"), \n  \"B/Plasma_cells\" = c(\"CD19\",\"MS4A1\",\"CD79A\",\"CD79B\",\"SDC1\",\"MZB1\",\"XBP1\",\"JCHAIN\"), \n  \"Myeloid\" = c(\"LYZ\",\"S100A8\",\"S100A9\",\"CD68\",\"CD14\",\"C1QB\",\"C1QC\"), \n  \"Endothelial\" = c(\"PECAM1\",\"VWF\",\"ENG\",\"MCAM\"), \n  \"Fibroblast\" = c(\"FAP\",\"PDPN\",\"COL1A2\",\"DCN\",\"COL3A1\",\"COL6A1\"),\n  \"Epithelial\" = c(\"EPCAM\",\"MUC1\",\"ERBB2\",\"KRT8\",\"PGC\",\"GKN2\",\"SLC5A5\",\"FABP1\",\"KRT20\")\n)\n\n\nseurat_object &lt;- AddModuleScore_UCell(\n  seurat_object,\n  ncores = 8,\n  features = cell_lineage_markers) \n\n\nFeaturePlot(\n  seurat_object, \n  reduction = \"umap\", \n  label = TRUE,\n  ncol = 2,\n  features = paste0(\n    names(cell_lineage_markers), \"_UCell\")\n  )"
  },
  {
    "objectID": "posts/2024-04-16/index.html#subsetting-nk-compartment-for-cytotrace-analysis",
    "href": "posts/2024-04-16/index.html#subsetting-nk-compartment-for-cytotrace-analysis",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "As expected the signature score derived from UCell can help us to annotate the distinct cell populations. The clusters #1, #7, and #15 are associated with NK and T-cells. This tutorial will consider that clusters #7 and #15 are populated by NK cells. Note, that cluster #15 displays both T and NK signatures, a common feature associated with NK/T-cells. However, we will ignore it for today :)\n\nnk_compartiment_object &lt;- subset(\n  seurat_object, subset = seurat_clusters %in% c(7, 15))\n\n\nnk_compartiment_counts &lt;- LayerData(\n    object = nk_compartiment_object, layer = \"counts\")\n\n\ncyto_results &lt;- CytoTRACE(nk_compartiment_counts)\n\n\nplotCytoTRACE(cyto_results)"
  },
  {
    "objectID": "posts/2024-04-16/index.html#extracting-less-differentiated-nk-cells",
    "href": "posts/2024-04-16/index.html#extracting-less-differentiated-nk-cells",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "CytoTRACE will rank the cell based on differentiation score, values ranging from 0 (more differentiated) to 1 (less differentiated).\n\n# Extracting UMAP coordinates\nnk_compartiment_embeddings &lt;- Embeddings(\n  nk_compartiment_object[[\"umap\"]]\n)\n\n# Adding UMAP and CytoTRACE score on metadata\nnk_compartiment_object &lt;- AddMetaData(\n  nk_compartiment_object,\n  nk_compartiment_embeddings\n)\n\nnk_compartiment_object@meta.data[['CytoTRACE']] &lt;- \n  cyto_results$CytoTRACE\n\nNext, we will leverage dbscan for selecting highly-dense clusters with CyTRACE scores higher or equal to 0.9.\n\n# Creating a data.frame with embeddings and CytoTrace score\ndata &lt;- nk_compartiment_object@meta.data[, c(\"umap_1\", \"umap_2\", \"CytoTRACE\")]\ndata &lt;- data %&gt;%\n  mutate(\n    filtered = ifelse(CytoTRACE &gt;= 0.9, \"Yes\", \"No\") \n  )\n\n\n# Subsetting only CytoTRACE higher than 0.9 (less differentiated)\nfiltered_data &lt;- data %&gt;%\n  filter(filtered == \"Yes\") %&gt;%\n  select(umap_1, umap_2)\n\n# Choose eps and minPts based on your dataset characteristics\nclustering &lt;- dbscan(filtered_data, eps = 0.5, minPts = 5)\n\n\n# Calculate k-nearest neighbors distance as a proxy for density\ndistances &lt;- kNNdist(filtered_data, k = 5)  # You might want to adjust this based on the density you expect\n\n# Add distances to your data frame\nfiltered_data$local_density = 1 / distances  # Inverse of distance to indicate density\n\n# Determine the candidate/representative for each cluster\ncluster_representatives &lt;- data.frame()\n\nfor (i in unique(clustering$cluster)) {\n  if (i &gt; 0) {  \n    \n    # Only consider non-noise clusters\n    cluster_data &lt;- filtered_data[clustering$cluster == i,]\n    \n    # Select the data point with the maximum local density\n    representative_index &lt;- which.max(cluster_data$local_density)\n    cluster_representatives &lt;- rbind(cluster_representatives, cluster_data[representative_index, ])\n  }\n}\n\nknitr::kable(cluster_representatives)\n\n\n\n\n\n\n\n\n\n\n\numap_1\numap_2\nlocal_density\n\n\n\n\nSPECTRUM-OV-009_S1_CD45P_RIGHT_UPPER_QUADRANT_AATCGACAGACGGTTG-1\n-7.502961\n3.156997\n15.18489\n\n\n\n\n\n\nggplot(data = data, aes(x = umap_1, y = umap_2)) +\n  geom_point(aes(color = filtered), alpha = 0.5) +\n  geom_point(data = cluster_representatives, color = \"black\", size = 5, shape = 17) +\n  scale_color_manual(values = c(\"grey\", \"blue\", \"black\"), labels = c(\"No\", \"Yes\", \"Candidate\")) +\n  labs(title = \"UMAP Plot\", x = \"UMAP 1\", y =\"UMAP 2\", color = \"Has high CytoTRACE score?\") +\n  theme_minimal() +\n  theme(legend.position = \"bottom\")\n\n\n\n\n\n\n\n\nOkey dokey! Now we have a decent candidate (black triangle) to be used as a root! We can finally focus on pseudotime analysis with Monocle3."
  },
  {
    "objectID": "posts/2024-04-16/index.html#preparing-monocle-object",
    "href": "posts/2024-04-16/index.html#preparing-monocle-object",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "monocle_object &lt;- as.cell_data_set(nk_compartiment_object)\nmonocle_object &lt;- cluster_cells(monocle_object)\nmonocle_object &lt;- learn_graph(monocle_object)\n\n\n# This will print out an unrooted trajectory\np0 &lt;- plot_cells(\n  monocle_object,\n  cell_size = 2,\n  label_groups_by_cluster = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np0"
  },
  {
    "objectID": "posts/2024-04-16/index.html#defining-pseudotime-root-based-on-differentiation-score",
    "href": "posts/2024-04-16/index.html#defining-pseudotime-root-based-on-differentiation-score",
    "title": "An automatic and biological-driven approach for defining ‚Äúroots‚Äù on Monocle3",
    "section": "",
    "text": "monocle_object &lt;- order_cells(\n  monocle_object, root_cells = row.names(cluster_representatives)) # Voil√†. We can add the cell_id here.\n\n\np1 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"pseudotime\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np2 &lt;- plot_cells(\n  monocle_object, \n  color_cells_by = \"CytoTRACE\", \n  cell_size = 2,\n  label_cell_groups = FALSE, \n  label_leaves = FALSE, \n  label_branch_points = FALSE\n  )\n\np1 + p2\n\n\n\n\n\n\n\n\nDone! We now have a basic workflow for defining pseudotime roots without manual intervention. The CytoTRACE + Monocle3 idea was originally published here.\n\n\n\nR version 4.3.0 (2023-04-21)\nPlatform: aarch64-apple-darwin22.4.0 (64-bit)\nRunning under: macOS Ventura 13.6.6\n\nMatrix products: default\nBLAS:   /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRblas.dylib \nLAPACK: /opt/local/Library/Frameworks/R.framework/Versions/4.3/Resources/lib/libRlapack.dylib;  LAPACK version 3.11.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: America/Chicago\ntzcode source: internal\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] dplyr_1.1.2                 ggplot2_3.4.2              \n [3] dbscan_1.1-11               UCell_2.6.2                \n [5] monocle3_1.3.4              SingleCellExperiment_1.23.0\n [7] SummarizedExperiment_1.31.1 GenomicRanges_1.53.1       \n [9] GenomeInfoDb_1.37.2         IRanges_2.35.2             \n[11] S4Vectors_0.39.1            MatrixGenerics_1.13.1      \n[13] matrixStats_1.0.0           Biobase_2.61.0             \n[15] BiocGenerics_0.47.0         SeuratWrappers_0.3.19      \n[17] Seurat_4.9.9.9045           SeuratObject_4.9.9.9084    \n[19] sp_2.0-0                   \n\nloaded via a namespace (and not attached):\n  [1] RcppAnnoy_0.0.21        splines_4.3.0           later_1.3.1            \n  [4] bitops_1.0-7            tibble_3.2.1            R.oo_1.25.0            \n  [7] polyclip_1.10-4         fastDummies_1.7.3       lifecycle_1.0.3        \n [10] rstatix_0.7.2           rprojroot_2.0.3         globals_0.16.2         \n [13] lattice_0.21-8          MASS_7.3-60             backports_1.4.1        \n [16] magrittr_2.0.3          plotly_4.10.2           rmarkdown_2.23         \n [19] yaml_2.3.7              remotes_2.4.2.1         httpuv_1.6.11          \n [22] sctransform_0.3.5       spam_2.9-1              spatstat.sparse_3.0-2  \n [25] reticulate_1.35.0       cowplot_1.1.1           pbapply_1.7-2          \n [28] minqa_1.2.5             RColorBrewer_1.1-3      abind_1.4-5            \n [31] zlibbioc_1.47.0         Rtsne_0.16              purrr_1.0.2            \n [34] R.utils_2.12.2          RCurl_1.98-1.12         GenomeInfoDbData_1.2.10\n [37] ggrepel_0.9.3           irlba_2.3.5.1           listenv_0.9.0          \n [40] spatstat.utils_3.0-3    terra_1.7-39            goftest_1.2-3          \n [43] RSpectra_0.16-1         spatstat.random_3.1-5   fitdistrplus_1.1-11    \n [46] parallelly_1.36.0       ncdf4_1.21              leiden_0.4.3           \n [49] codetools_0.2-19        DelayedArray_0.27.10    tidyselect_1.2.0       \n [52] farver_2.1.1            viridis_0.6.4           lme4_1.1-34            \n [55] spatstat.explore_3.2-1  jsonlite_1.8.7          BiocNeighbors_1.19.0   \n [58] ellipsis_0.3.2          progressr_0.13.0        ggridges_0.5.4         \n [61] survival_3.5-5          tools_4.3.0             ica_1.0-3              \n [64] Rcpp_1.0.11             glue_1.6.2              gridExtra_2.3          \n [67] SparseArray_1.1.11      xfun_0.39               here_1.0.1             \n [70] withr_2.5.0             BiocManager_1.30.21.1   fastmap_1.1.1          \n [73] HiClimR_2.2.1           boot_1.3-28.1           fansi_1.0.4            \n [76] egg_0.4.5               digest_0.6.33           rsvd_1.0.5             \n [79] R6_2.5.1                mime_0.12               colorspace_2.1-0       \n [82] scattermore_1.2         tensor_1.5              spatstat.data_3.0-1    \n [85] R.methodsS3_1.8.2       utf8_1.2.3              tidyr_1.3.0            \n [88] generics_0.1.3          data.table_1.14.8       robustbase_0.99-0      \n [91] httr_1.4.6              htmlwidgets_1.6.2       S4Arrays_1.1.5         \n [94] uwot_0.1.16             pkgconfig_2.0.3         gtable_0.3.3           \n [97] lmtest_0.9-40           XVector_0.41.1          pcaPP_2.0-3            \n[100] htmltools_0.5.5         carData_3.0-5           dotCall64_1.0-2        \n[103] scales_1.2.1            png_0.1-8               knitr_1.43             \n[106] rstudioapi_0.15.0       reshape2_1.4.4          nlme_3.1-162           \n[109] nloptr_2.0.3            proxy_0.4-27            zoo_1.8-12             \n[112] stringr_1.5.0           KernSmooth_2.23-22      parallel_4.3.0         \n[115] miniUI_0.1.1.1          pillar_1.9.0            grid_4.3.0             \n[118] vctrs_0.6.3             RANN_2.6.1              ggpubr_0.6.0           \n[121] promises_1.2.0.1        car_3.1-2               xtable_1.8-4           \n[124] cluster_2.1.4           evaluate_0.21           mvtnorm_1.2-2          \n[127] cli_3.6.1               compiler_4.3.0          rlang_1.1.1            \n[130] crayon_1.5.2            leidenbase_0.1.25       ggsignif_0.6.4         \n[133] future.apply_1.11.0     labeling_0.4.2          plyr_1.8.8             \n[136] stringi_1.7.12          nnls_1.5                viridisLite_0.4.2      \n[139] deldir_1.0-9            BiocParallel_1.35.3     assertthat_0.2.1       \n[142] ccaPP_0.3.3             munsell_0.5.0           lazyeval_0.2.2         \n[145] spatstat.geom_3.2-4     Matrix_1.6-0            RcppHNSW_0.4.1         \n[148] patchwork_1.1.2         future_1.33.0           shiny_1.7.4.1          \n[151] ROCR_1.0-11             broom_1.0.5             igraph_1.5.1           \n[154] DEoptimR_1.1-0         \n\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-04-11/index.html",
    "href": "posts/2024-04-11/index.html",
    "title": "Clinical application of bronchoalveolar lavage fluid metagenomics next-generation sequencing in cancer patients with severe pneumonia",
    "section": "",
    "text": "Graphical abstract summarising the main findings from Wang et al, 2024 paper.\n\n\nSevere pneumonia presents a significant challenge for cancer patients, often complicating timely and accurate diagnosis of underlying pathogens. Conventional diagnostic approaches can be sluggish and may overlook crucial infections, particularly in individuals with compromised immune systems. However, the advent of metagenomic next-generation sequencing (mNGS) is revolutionizing diagnostic protocols by expediting accurate identification and bypassing the need for additional clinical assessments such as Gram staining, serum immunological tests, G tests, GM tests, and PCR tests.\nIn a study targeting cancer patients grappling with severe pneumonia, Wang et al. (Wang et al. 2024) harnessed mNGS to scrutinize lung fluid in conjunction with standard culture techniques. Their findings underscored mNGS‚Äôs superior efficacy in detecting infections, even discerning multiple microorganisms simultaneously. Notably, it excelled in identifying elusive pathogens like Streptococcus pneumoniae and Aspergillus, which often elude traditional diagnostic methods.\nThe research demonstrated that mNGS results prompted treatment adjustments for over half of the patients, leading to improved clinical outcomes. By furnishing clinicians with precise information regarding the causative agents, mNGS facilitated targeted antibiotic or antifungal therapy selection.\nAlthough mNGS shows great promise, it does have some drawbacks. It can be expensive, and there are still technical issues to work out. Also, because it‚Äôs very sensitive, it can‚Äôt always tell if something is contamination, colonization, or an actual infection. Still, the study shows that mNGS can really help doctors diagnose and treat infections in cancer patients with severe pneumonia. This new tool helps healthcare workers handle these serious illnesses better, which should lead to better outcomes in the future.\n\n\n\n\nReferences\n\nWang, Chao, Xiaojuan Yin, Wenqing Ma, Li Zhao, Xuhong Wu, Nan Ma, Yuepeng Cao, et al. 2024. ‚ÄúClinical Application of Bronchoalveolar Lavage Fluid Metagenomics Next-Generation Sequencing in Cancer Patients with Severe Pneumonia.‚Äù Respiratory Research 25 (1): 68. https://doi.org/10.1186/s12931-023-02654-5."
  },
  {
    "objectID": "posts/2024-03-08/index.html",
    "href": "posts/2024-03-08/index.html",
    "title": "Why to sequence the DNA?",
    "section": "",
    "text": "There are many different DNA sequencing technologies, all of them with their potentialities. However, do you know some of the main use cases for DNA sequencing?\n\n\n\nDesigned by Freepik\n\n\nüß¨ Genomic research: By sequencing the whole genome (WGS) or the exome (WES), one can understand the organism‚Äôs genetic architecture;\nüíâ Medical diagnostics: DNA sequencing can identify mutations and variations associated with genetic disorders, allowing for early diagnosis and personalized treatment plans;\nüíä Pharmacogenomics: Understanding how an individual‚Äôs genetic makeup influences their response to drugs helps tailor medication plans for maximum efficacy and minimal side effects;\nüïµÔ∏è‚Äç‚ôÇÔ∏è Forensic analysis: DNA sequencing is used in forensic investigations to identify individuals, establish paternity, and solve criminal cases by analyzing biological evidence such as hair, blood, or saliva.\nüë™ Ancestry and Genealogy: DNA sequencing, particularly in the form of consumer genetic testing, is used to trace familial and ancestral relationships, providing insights into personal heritage and ancestry;\nü¶† Microbial and environmental analysis: Sequencing the genomes of bacteria, viruses, and other microorganisms helps understand their biology and develop targeted treatments. Also, with DNA sequencing, it is possible to identify microorganisms in environmental samples, such as soil or water, helps monitor biodiversity, identify species presence, and assess ecosystem health;\nü¶¥ Evolutionary Biology: Sequencing the genome of viruses and bacteria allows us to develop more precise hypotheses regarding the spread of pathogens responsible for the development of infectious diseases. Also sequencing ancient DNA from fossils and archaeological remains contributes to our understanding of evolutionary processes and the history of life on Earth.\nThe Lexanomics team is experienced in all DNA sequencing analyses. If you want to know more about them, contact us! #DNAsequencing #Bioinformatics #Lexanomics üß¨üî¨üìä"
  },
  {
    "objectID": "posts/2024-03-19/index.html",
    "href": "posts/2024-03-19/index.html",
    "title": "The butterfly effect: lncRNAs in the evolutionists‚Äô sights",
    "section": "",
    "text": "Flying insects have been starring the study of evolution. The story of how moths with darker color increased frequency in contrast to light color moths in the highly polluted 1900‚Äôs Manchester is a well-known example of the relationship of natural selection and evolution.\nProtein coding genes are the main subjects of evolutionary studies, since they are directly implicated into protein production. However, another class of genes might need more attention. This time, a mutant butterfly caught the researchers attention.\n\n\n\nHeliconius melpomene, a butterfly which was the subject of the studies. Image by wirestock on Freepik\n\n\nThe discovery of a mutant butterfly on eBay has led to a breakthrough in understanding how butterfly wings develop their diverse patterns of colors. Previously, a protein-encoding gene called cortex was thought to be responsible, but new research has revealed that a different gene, which produces an lncRNA, is the key regulator. Evolutionary biologists discovered that a long noncoding RNA (lncRNA) controls the color patterns in butterfly wings. They found this by studying white-winged Heliconius butterflies and disabling the lncRNA gene in painted lady butterflies, which resulted in white-winged offspring. This lncRNA also controls pigmentation in other butterfly species. Another team found similar results in buckeye butterflies, where CRISPR editing of the lncRNA affected wing color and seasonal changes in color. Additionally, researchers in Singapore found that a microRNA regulates black wing patterns in squinting bush brown butterflies (Trivedi 2021; Fandino et al. 2024).\nThese findings highlight the role of RNA, rather than proteins, in controlling visible traits in butterflies. This is the first time that long noncoding RNA (lncRNA) has been linked to the evolution of a visible trait in animals, suggesting that noncoding RNA plays a crucial role in genetic regulation.\n\n\n\n\nReferences\n\nFandino, Richard A., Noah K. Brady, Martik Chatterjee, Jeanne M. C. McDonald, Luca Livraghi, Karin R. L. van der Burg, Anyi Mazo-Vargas, Eirene Markenscoff-Papadimitriou, and Robert D. Reed. 2024. ‚ÄúThe Ivory lncRNA Regulates Seasonal Color Patterns in Buckeye Butterflies.‚Äù bioRxiv. https://doi.org/10.1101/2024.02.09.579733.\n\n\nTrivedi, Y. 2021. ‚ÄúSurprise RNAs Solve Mystery of How Butterfly Wings Get Their Colorful Patterns.‚Äù Science 373 (6554): 1234‚Äì37. https://doi.org/10.1126/science.abcd1234."
  },
  {
    "objectID": "posts/2024-03-02/index.html",
    "href": "posts/2024-03-02/index.html",
    "title": "Jumping genetic element getting in the way of primates tail evolution",
    "section": "",
    "text": "It is of common knowledge that humans and monkeys share great similarities regarding their genomes. And, if most monkeys have tails, what happend to ours? This is the central question Xia and colleagues (Xia et al. 2024) try to answer.\nAfter comparing the genomic sequences across primates, the researchers found a mobile genetic element called Alu only inserted on the gene TBXT of apes, a gene that encodes for a transcription factor associated with tail development in mammals. Alu elements have the ability of ‚Äúteleporting‚Äù and fixating in other genome regions and therefore they are very important to diversify genome sequences. The Alu element insertion found in apes leads to an alternative splicing event, resulting in the production of a shortened form of the TBXT gene. Humans express both the full-length and the shortened versions of TBXT gene.\n\n\n\nEvolution of tails in primates. Figure from Xia et al, 2024.\n\n\nTo test their hypothesis, researchers engineered mice to express these two gene versions and they observed that, in this scenario, mice exhibit a lack of a tail or a shortened tail, similar to the tail-loss phenotype in hominoids. However, for mice engineered to have only the shortened version of TBXT gene died during the embryonic development. This suggests that the evolution of tail loss in hominoids may have been associated with an adaptive trade-off, where the loss of the tail conferred evolutionary advantages but also increased the risk of neural tube defects.\n\n\n\nFrom SMBC comics (https://www.smbc-comics.com/).\n\n\nThis research is a great example of comparative genome analysis, common in the Bioinformatics area. Do you need help in comparing genomes? Talk to the Lexanomics team!\n\n\n\n\nReferences\n\nXia, B., W. Zhang, G. Zhao, et al. 2024. ‚ÄúOn the Genetic Basis of Tail-Loss Evolution in Humans and Apes.‚Äù Nature 626: 1042‚Äì48. https://doi.org/10.1038/s41586-024-07095-8."
  },
  {
    "objectID": "posts/2024-02-29/index.html",
    "href": "posts/2024-02-29/index.html",
    "title": "Analysing the cell transcriptional profile at the single-cell resolution",
    "section": "",
    "text": "Single-cell RNA-seq analysis is a powerful technique used in biology and medicine to study the gene expression of individual cells within a population. Single-cell gene expression analysis and bulk RNA-seq differ primarily in the scale and resolution of the analysis. Single-cell gene expression analysis focuses on individual cells, providing insights into cellular heterogeneity and rare cell populations. In contrast, bulk RNA-seq measures the average gene expression of a population of cells, masking cellular diversity. Single-cell analysis requires specialized methods to isolate and analyze individual cells, while bulk RNA-seq is more straightforward and commonly used for analyzing gene expression in larger cell populations.\nBesides producing beautiful visualizations (La Manno et al. 2021), single-cell data has revolutionized the information regarding cell biology, with direct applications to the understanding of cell development and human diseases.\n\n\n\nt-SNE representation for cell types development in mouse brain. Figure from (La Manno et al. 2021).\n\n\nHere‚Äôs some use cases for single-cell data:\n\nCellular Heterogeneity üß¨: Understand the complex biological processes such as development, disease progression, and immune responses.\nDevelopmental Biology üå±: Insights into the molecular mechanisms underlying cell differentiation and development.\nCancer Research ü¶†: Study tumor heterogeneity, identify rare subpopulations of cells, and track the evolution of cancer cells over time or in response to treatment.\nNeuroscience üß†: Map the cellular diversity of the brain, identify different cell types, and understand how they function in both healthy and diseased states.\nImmunology ü¶†: Study immune cell diversity, activation states, and responses to stimuli.\nStem Cell Biology üå±: Study the properties of stem cells, such as self-renewal and differentiation potential, and identify markers for specific cell types.\nDrug Discovery and Development üíä: Identify new drug targets, understand drug resistance mechanisms, and optimize drug development pipelines.\n\nSingle-cell opened a world to new discoveries. Do you need help with analysing single-cell data? Schedule a meeting with the Lexanomics consultants!\n\n\n\n\nReferences\n\nLa Manno, Gioele, Kimberly Siletti, Alessandro Furlan, Daniel Gyllborg, Elin Vinsland, Alejandro Mossi Albiach, Christoffer Mattsson Langseth, et al. 2021. ‚ÄúMolecular Architecture of the Developing Mouse Brain.‚Äù Nature 596 (7870): 92‚Äì96. https://doi.org/10.1038/s41586-021-03775-x."
  },
  {
    "objectID": "posts/2024-04-02/index.html",
    "href": "posts/2024-04-02/index.html",
    "title": "Redefining the treponemal history through pre-Columbian genomes from Brazil",
    "section": "",
    "text": "It‚Äôs no secret that human migration dynamics are one of the primary factors responsible for the introduction of infectious agents to different parts of the planet. Historically, venereal syphilis is known to have caused a devastating outbreak in Europe in the late 15th century, leading to the widely accepted hypothesis that Treponema pallidum subsp. pallidum was introduced to the Americas during the colonization events led by Christopher Columbus.\nContradictorily, based on fossil findings, paleontologists have been proposing the hypothesis that treponemal infections occurred in the Americas since pre-Columbian times. However, as these are only fossil findings, paleopathological evidence is often considered contradictory and unreliable.\nTo finally clarify this topic, a group of researchers with expertise in Paleontology, Molecular Biology, and Bioinformatics conducted a study recently published in Nature, titled ‚ÄúRedefining the treponemal history through pre-Columbian genomes from Brazil.‚Äù(Majander et al. 2024) In this study, 99 fossil specimens from an archaeological site called Jabuticabeira II, located in the Laguna region of Santa Catarina on the Brazilian coast, were examined. These fossils were searched for signs of periostitis, bone remodeling, and ‚Äúmoth-eaten‚Äù marks, which are classic indicators of treponemal infections. At the end of the screening, 12 specimens were from individuals with these pathologies; however, only 4, from different individuals, provided sufficient genomic data for subsequent analysis.\nShotgun genomic data were filtered using the Kraken tool, with its respective default database, revealing that among the sequenced material, there were reads belonging to the Treponema family. After several stages of genomic material enrichment for T. pallidum, it was possible to fully reconstruct the genome of three subspecies. The genomes were aligned with others available in public databases and subjected to molecular clock dating techniques, revealing that one of the sublineage genomes dated back to between 780 BC and 449 AD.\n\n\n\nCompiled results from Majander et al.¬†2024\n\n\nThe findings also identified numerous recombination events among Treponema subspecies, which are classically known as a key mechanism in bacterial evolution. Thus, the groundbreaking discovery of a pre-Columbian treponematosis, stemming from a combination of ancient pathogen genomics and the careful selection of archaeological samples, sheds light on the events leading to the emergence and spread of venereal syphilis and helps resolve the evolutionary factors responsible for the global success of the Treponema family.\n\n\n\n\nReferences\n\nMajander, Kerttu, Marta Pla-D√≠az, Louis Du Plessis, Natasha Arora, Jose Filippini, Luis Pezo-Lanfranco, Sabine Eggers, Fernando Gonz√°lez-Candelas, and Verena J. Schuenemann. 2024. ‚ÄúRedefining the Treponemal History Through Pre-Columbian Genomes from Brazil.‚Äù Nature 627 (8002): 182‚Äì88. https://doi.org/10.1038/s41586-023-06965-x."
  },
  {
    "objectID": "posts/2024-04-09/index.html",
    "href": "posts/2024-04-09/index.html",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "",
    "text": "Suppose that we have a set of differentially expressed genes (DEG) from RNA-Seq data and their corresponding log2FoldChanges. Let‚Äôs create a protein-protein interaction (PPI) network with StringDB using some R packages. By combining PPI information and gene expression, we can have insights about how the DEGs can impact (or be impacted by) other genes.\nYou can download the data from this tutorial here."
  },
  {
    "objectID": "posts/2024-04-09/index.html#step-1-retrieve-the-ppi-network-from-stringdb",
    "href": "posts/2024-04-09/index.html#step-1-retrieve-the-ppi-network-from-stringdb",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "Step 1: Retrieve the PPI network from StringDB",
    "text": "Step 1: Retrieve the PPI network from StringDB\nBefore starting, you‚Äôll need to install and load the following packages:\n\nlibrary(RedeR)\nlibrary(igraph)\n\nLet‚Äôs import the table with the DEGs. In this table there is a column for gene symbols and another column for their corresponding log2FoldChanges.\n\ndegs &lt;- read.csv(\"exp-table.csv\")\nhead(degs)\n\n   genes     log2fc\n1   ACLY  0.6864199\n2   ACO1 -1.4629591\n3   ACO2 -3.7851444\n4     CS  2.0569852\n5 DHTKD1  3.0715545\n6   DLAT  1.8612732\n\n\nWe‚Äôre using the stringDB API to retrieve PPI information (for more information of each API‚Äôs methods, visit https://string-db.org/help/api/).\nThe first method to be used is the get_string_ids, which will map a list of genes to the stringDB‚Äôs identifiers (https://string-db.org/cgi/help.pl?subpage=api%23mapping-identifiers.\nWhen submitting a request to the stringDB API programmatically, we need to concatenate the identifiers by the symbol ‚Äú%0d‚Äù (this is the standard separator for gene names).\n\ngenes &lt;- paste0(degs$genes, collapse = \"%0d\")\n\nNow we can make a request with the postForm function from the RCurl package. An important parameter is the species, which stands for the NCBI taxonomy ID for the genes/proteins we‚Äôre considering. In this case, we are dealing with human genes (taxid: 9606).\n\nreq &lt;- RCurl::postForm(\n  \"https://string-db.org/api/tsv/get_string_ids\",\n  identifiers = genes, # gene names\n  echo_query = \"1\",\n  species = \"9606\" # homo sapiens taxid\n)\nids_mapped &lt;- read.table(text = req, sep = \"\\t\", header = T, quote = \"\")\n\nhead(ids_mapped[,1:3])\n\n  queryItem queryIndex             stringId\n1      ACLY          0 9606.ENSP00000466259\n2      ACO1          1 9606.ENSP00000309477\n3      ACO2          2 9606.ENSP00000216254\n4        CS          3 9606.ENSP00000342056\n5    DHTKD1          4 9606.ENSP00000263035\n6      DLAT          5 9606.ENSP00000280346\n\n\nWe mapped each gene name to their corresponding proteins annotated on the StringDB (the stringId column). Now, let‚Äôs use these StringIDs to retrieve the interaction information:\n\nstringids &lt;- paste0(unique(ids_mapped$stringId), collapse = \"%0d\")\n\nreq &lt;- RCurl::postForm(\n  \"https://string-db.org/api/tsv/network\",\n  identifiers = stringids, # stringids \n  required_core = \"0\", # minimal score\n  species     = \"9606\"  # homo sapiens taxid\n)\n\nppi &lt;- read.table(text = req, sep = \"\\t\", header = T)\nhead(ppi[,1:2])\n\n            stringId_A           stringId_B\n1 9606.ENSP00000216254 9606.ENSP00000258886\n2 9606.ENSP00000216254 9606.ENSP00000223366\n3 9606.ENSP00000216254 9606.ENSP00000297283\n4 9606.ENSP00000216254 9606.ENSP00000295266\n5 9606.ENSP00000216254 9606.ENSP00000290573\n6 9606.ENSP00000216254 9606.ENSP00000264663\n\n\nThe dataframe represents a network format called edge list. It represents the interaction between the proteins on the stringId_A column and the proteins on the stringId_B column. For example, the protein 9606.ENSP00000216254 interacts with the protein 9606.ENSP00000258886. The interaction information of a given protein A and a protein B comes from different sources or channels. StringDB returns the following channels:\nscore: combined score\nnscore: gene neighborhood score\nfscore: gene fusion score\npscore: phylogenetic profile score\nascore: coexpression score\nescore: experimental score\ndscore: database score\ntscore: textmining score\nAs you guessed, the combined score represents the score combination of all other channels. We then can select the interactions based on a combined score of 0.7 (you can choose other channels as a reference for the interactions):\n\nppi &lt;- subset(ppi, ppi$score &gt;= 0.7)\nnrow(ppi)\n\n[1] 375\n\n\nThis leaves us with 375 interactions reported for the proteins retrieved from our initial DEGs list."
  },
  {
    "objectID": "posts/2024-04-09/index.html#step-2-plot-the-ppi-network-with-reder",
    "href": "posts/2024-04-09/index.html#step-2-plot-the-ppi-network-with-reder",
    "title": "Creating a PPI network from a list of differentially expressed genes",
    "section": "Step 2: Plot the PPI network with RedeR",
    "text": "Step 2: Plot the PPI network with RedeR\nRedeR is an R/Bioconductor package suitable to plot and manipulate networks. It presents a friendly interface to facilitate network customization (See the vignette for the complete guideline).\nFirst, let‚Äôs create a dataframe holding the information regarding each gene, their associated protein, and the log2FC:\n\nannotation &lt;- merge(degs,\n                    ids_mapped[, c(\"queryItem\", \"stringId\")],\n                    by.x = \"genes\", \n                    by.y = \"queryItem\")\nhead(annotation)\n\n   genes     log2fc             stringId\n1   ACLY  0.6864199 9606.ENSP00000466259\n2   ACO1 -1.4629591 9606.ENSP00000309477\n3   ACO2 -3.7851444 9606.ENSP00000216254\n4     CS  2.0569852 9606.ENSP00000342056\n5 DHTKD1  3.0715545 9606.ENSP00000263035\n6   DLAT  1.8612732 9606.ENSP00000280346\n\n\nNow, let‚Äôs use the igraph package to create the network. igraph is a multilanguage API created to represent data as networks. If you want to know more about the igraph R interface, see their vignette: https://r.igraph.org/. Here, we used the directed = FALSE argument because PPI networks are undirected networks.\n\ngraph &lt;- igraph::graph_from_data_frame(ppi[, c(\"stringId_A\", \"stringId_B\")], directed = FALSE)\nplot(graph)\n\n\n\n\n\n\n\n\nThis is not great, the aesthetics can be improved. Now, let‚Äôs associate the annotation data.frame we constructed before with the igraph object we created:\n\ngraph &lt;- RedeR::att.mapv(graph, dat = annotation, refcol = 3)\n\nThe att.mapv function associates node information from the annotation dataframe to the graph. The refcol argument specifies which column on the annotation dataframe corresponds to the node ID used to build the graph (in this case, we used the stringID, the third column on the annotation dataframe). This is the reference column that will be used to set other attributes to our network.\nUsually, it is more informative to represent the nodes as gene names. Let‚Äôs also color the nodes following the log2FC scale. To do that, let‚Äôs set those attributes on the graph we created with the att.setv function:\n\ngraph &lt;- RedeR::att.setv(graph, from = \"genes\", to = \"nodeAlias\")\ngraph &lt;- RedeR::att.setv(graph, from = \"log2fc\", to = \"nodeColor\", breaks = seq(-2, 2, 0.4), pal = 2)\n\nNow, we launch the RedeR interface and we add the network to it:\n\n# Launch RedeR\nrdp &lt;- RedPort()\ncalld(rdp)\n\n# Add graph to RedeR interface\naddGraph(rdp, graph)\n\nFrom there, you can play around with your network and display the nodes as you wish by clicking and dragging them. Or you can hit the ‚ÄúStart relax‚Äù button and the RedeR will look for an optimal layout for your network. This is specially useful for big networks. You can test different force parameters and see how it affects your network layout.\n\nAt last, let‚Äôs add a legend for color scale:\n\nscl &lt;- graph$legNodeColor$scale\nleg &lt;- graph$legNodeColor$legend \naddLegend.color(rdp, \n                colvec = scl, \n                labvec = leg, \n                title = \"log2FC\")\n\n\nAnd voil√†! You can save the network image by clicking in ‚ÄúFile‚Äù &gt; ‚ÄúExport‚Äù &gt; ‚ÄúImage‚Äù and chosing the desired format."
  },
  {
    "objectID": "posts/2024-03-28/index.html",
    "href": "posts/2024-03-28/index.html",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "For the series on basic, but useful tips on single-cell analysis. We want to introduce parallelization using future for Seurat.\nFrequently a bioinformatician/computational biologist needs to test multiple parameters in a single-cell project, e.g., evaluating clustering resolutions. Although a conventional task, this procedure could take a while ranging from minutes to hours‚Ä¶ It can get even worse if we talk about differential expressions analysis with well-known FindAllMarkers.\nLife is short, and I want my results. That being said, why not use parallelization? To our surprise, not many data analysts are familiar with the future package [1]. Furthermore, the future package is very handy for R package development - Yes, it is not limited to Seurat, you could incorporate it into your package/script.\n\n\n\n\n\n\n\n\nAs for Seurat, there are at least six (06) functions that were written to leverage future parallelization.\n\nNormalizeData\nScaleData -JackStraw\nFindMarkers*\nFindIntegrationAnchors\nFindClusters*\n\n*For teaching purposes we will focus only on these two functions.\n\n\n\nlibrary(Seurat)\nlibrary(dplyr)\nlibrary(future)\n\nPlease note that we need to establish what parallelization strategy (plan) will be used in our analysis. Also, we are running multiple processes in parallel which can dramatically increase the memory consumption. Be thoughtful about it.\n\n# Setting memory limit for 8Gb\noptions(future.globals.maxSize = 8000 * 1024^2)\n\n# Enabling parallelization\nplan(\"multicore\", workers = 4) # To the date, RStudio does not support parallelization. Run this script using Rscript command-line application.\n\nNext, we will load the PBMC dataset from 10X Genomics. Available here\n\npbmc_seurat &lt;- readRDS(file = \"path/to/pbmc_seurat.RDS\")\npbmc_seurat\n\n\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data\n\n\n\n\n\n\npbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\npbmc_seurat &lt;- RunPCA(pbmc_seurat)\n\n\n\n\nAs mentioned, often a bioinformatician will evaluate with multiple clustering resolutions. In this tutorial, we will do such a task considering eight different thresholds.\n\npbmc_seurat &lt;- FindNeighbors(pbmc_seurat, dims = 1:10)\npbmc_seurat &lt;- FindClusters(pbmc_seurat, \n                            resolution = c(0.1, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0))\n\n\n\n\nFinally, we will execute the differential expression analysis.\n\npbmc_markers &lt;- FindAllMarkers(pbmc_seurat, only.pos = TRUE)\n\n\npbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    dplyr::filter(avg_log2FC &gt; 1)\n\n# A tibble: 2,830 √ó 7\n# Groups:   cluster [11]\n      p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 4.62e-91       1.08 0.954 0.609  6.33e-87 0       LDHB     \n 2 1.94e-89       2.11 0.517 0.124  2.66e-85 0       CCR7     \n 3 1.68e-52       1.76 0.396 0.117  2.30e-48 0       PRKCQ-AS1\n 4 9.77e-52       1.83 0.388 0.114  1.34e-47 0       LEF1     \n 5 1.77e-43       1.89 0.323 0.09   2.42e-39 0       MAL      \n 6 2.61e-43       2.05 0.235 0.048  3.58e-39 0       FHIT     \n 7 3.45e-42       1.37 0.488 0.196  4.74e-38 0       PIK3IP1  \n 8 1.41e-40       1.05 0.677 0.373  1.93e-36 0       NOSIP    \n 9 1.51e-37       1.20 0.448 0.184  2.08e-33 0       TCF7     \n10 1.83e-35       1.57 0.244 0.063  2.51e-31 0       TRABD2A  \n# ‚Ñπ 2,820 more rows\n\n\nAnother lazy tip: If you are interested in assessing a preliminary result, you could combine the parallelization strategy with the parameter max.cells.per.ident from FindAllMarkers. It will downsample each cluster/ident based on the selected threshold.\n\npbmc_markers &lt;- FindAllMarkers(\n  pbmc_seurat, \n  max.cells.per.ident = 100, # for real datasets you should considered 1000 cells\n  only.pos = TRUE)\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-03-28/index.html#loading-requirements",
    "href": "posts/2024-03-28/index.html#loading-requirements",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "library(Seurat)\nlibrary(dplyr)\nlibrary(future)\n\nPlease note that we need to establish what parallelization strategy (plan) will be used in our analysis. Also, we are running multiple processes in parallel which can dramatically increase the memory consumption. Be thoughtful about it.\n\n# Setting memory limit for 8Gb\noptions(future.globals.maxSize = 8000 * 1024^2)\n\n# Enabling parallelization\nplan(\"multicore\", workers = 4) # To the date, RStudio does not support parallelization. Run this script using Rscript command-line application.\n\nNext, we will load the PBMC dataset from 10X Genomics. Available here\n\npbmc_seurat &lt;- readRDS(file = \"path/to/pbmc_seurat.RDS\")\npbmc_seurat\n\n\n\nAn object of class Seurat \n13714 features across 2700 samples within 1 assay \nActive assay: RNA (13714 features, 2000 variable features)\n 3 layers present: counts, data, scale.data"
  },
  {
    "objectID": "posts/2024-03-28/index.html#normalization-and-dimensionality-reduction",
    "href": "posts/2024-03-28/index.html#normalization-and-dimensionality-reduction",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "pbmc_seurat &lt;- pbmc_seurat %&gt;%\n  NormalizeData(normalization.method = \"LogNormalize\", scale.factor = 10000) %&gt;%\n  FindVariableFeatures(selection.method = \"vst\", nfeatures = 2000) %&gt;%\n  ScaleData()\n\n\npbmc_seurat &lt;- RunPCA(pbmc_seurat)"
  },
  {
    "objectID": "posts/2024-03-28/index.html#clustering",
    "href": "posts/2024-03-28/index.html#clustering",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "As mentioned, often a bioinformatician will evaluate with multiple clustering resolutions. In this tutorial, we will do such a task considering eight different thresholds.\n\npbmc_seurat &lt;- FindNeighbors(pbmc_seurat, dims = 1:10)\npbmc_seurat &lt;- FindClusters(pbmc_seurat, \n                            resolution = c(0.1, 0.25, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0))"
  },
  {
    "objectID": "posts/2024-03-28/index.html#differential-expression",
    "href": "posts/2024-03-28/index.html#differential-expression",
    "title": "Parallelization tips on Seurat",
    "section": "",
    "text": "Finally, we will execute the differential expression analysis.\n\npbmc_markers &lt;- FindAllMarkers(pbmc_seurat, only.pos = TRUE)\n\n\npbmc_markers %&gt;%\n    group_by(cluster) %&gt;%\n    dplyr::filter(avg_log2FC &gt; 1)\n\n# A tibble: 2,830 √ó 7\n# Groups:   cluster [11]\n      p_val avg_log2FC pct.1 pct.2 p_val_adj cluster gene     \n      &lt;dbl&gt;      &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;fct&gt;   &lt;chr&gt;    \n 1 4.62e-91       1.08 0.954 0.609  6.33e-87 0       LDHB     \n 2 1.94e-89       2.11 0.517 0.124  2.66e-85 0       CCR7     \n 3 1.68e-52       1.76 0.396 0.117  2.30e-48 0       PRKCQ-AS1\n 4 9.77e-52       1.83 0.388 0.114  1.34e-47 0       LEF1     \n 5 1.77e-43       1.89 0.323 0.09   2.42e-39 0       MAL      \n 6 2.61e-43       2.05 0.235 0.048  3.58e-39 0       FHIT     \n 7 3.45e-42       1.37 0.488 0.196  4.74e-38 0       PIK3IP1  \n 8 1.41e-40       1.05 0.677 0.373  1.93e-36 0       NOSIP    \n 9 1.51e-37       1.20 0.448 0.184  2.08e-33 0       TCF7     \n10 1.83e-35       1.57 0.244 0.063  2.51e-31 0       TRABD2A  \n# ‚Ñπ 2,820 more rows\n\n\nAnother lazy tip: If you are interested in assessing a preliminary result, you could combine the parallelization strategy with the parameter max.cells.per.ident from FindAllMarkers. It will downsample each cluster/ident based on the selected threshold.\n\npbmc_markers &lt;- FindAllMarkers(\n  pbmc_seurat, \n  max.cells.per.ident = 100, # for real datasets you should considered 1000 cells\n  only.pos = TRUE)\n\n\n\nThe figures are derived from 1, and 2"
  },
  {
    "objectID": "posts/2024-02-28/index.html",
    "href": "posts/2024-02-28/index.html",
    "title": "A new look into microorganisms by the lens of metagenomics",
    "section": "",
    "text": "Have you ever heard that a great percentage of our body composition comes from the microorganisms living with us? Recent research suggests a 1:1 ratio for the number of microorganisms and human cells in the body (Sender, Fuchs, and Milo 2016). We coexist with several species of microorganisms and, therefore, our physiology is greatly influenced by these tiny beings. But can we study them all at once?\n\n\n\nDesigned by Freepik\n\n\nYes! That‚Äôs when metagenomics comes to the rescue! Metagenomics is a relatively recent field of study within genetics and microbiology that involves the analysis of genetic material collected directly from human or environmental samples. The key principle behind metagenomics is the sequencing and analysis of DNA or RNA from an entire microbial community, without the need for isolating and culturing individual organisms. Here‚Äôs some applications for metagenomics:\nHuman Microbiome Research: üë©‚Äçüî¨ Metagenomics sheds light on the diverse microbial communities residing within us, influencing health, disease, and personalized medicine;\nClinical Diagnostics: üè• Rapid identification of pathogens in clinical samples aids in disease diagnosis, treatment, and surveillance, bolstering public health efforts;\nBiodiversity Conservation: ü¶†Assess microbial diversity in threatened habitats, aiding in conservation planning and restoration efforts;\nEnsuring Food Safety: üçΩÔ∏è Detect foodborne pathogens, spoilage organisms, and authenticate food products, ensuring safety and quality;\nForensic Analysis: üïµÔ∏è‚Äç‚ôÇÔ∏è Analyze microbial signatures associated with crime scenes, human remains, and environmental samples, enhancing forensic science capabilities;\nEnvironmental Microbiology: üåç Metagenomics unveils insights into ecosystems, aiding conservation efforts and sustainable resource management;\nBioremediation Solutions: üõ†Ô∏è Metagenomics identifies microbial candidates capable of degrading pollutants, paving the way for effective bioremediation strategies;\nAdvancing Agriculture: üåæ Metagenomics guides precision farming practices, enhancing crop productivity, and fostering sustainable agriculture‚Ä¶\n‚Ä¶ and many more! Really, the sky‚Äôs the limit for metagenomics applications. Do want help with metagenomics analyses? The Lexanomics team is here to help you! #Bioinformatics #Metagenomics #Lexanomics\n\n\n\n\nReferences\n\nSender, Ron, Shai Fuchs, and Ron Milo. 2016. ‚ÄúAre We Really Vastly Outnumbered? Revisiting the Ratio of Bacterial to Host Cells in Humans.‚Äù Cell 164 (3): 337‚Äì40. https://doi.org/https://doi.org/10.1016/j.cell.2016.01.013."
  },
  {
    "objectID": "posts/2024-04-04/index.html",
    "href": "posts/2024-04-04/index.html",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "",
    "text": "Basic taxonomic classification of long and short reads with Kraken2\nThe taxonomic classification of reads from sequencing experiments has become a common task for most computational biology and bioinformatics projects. To facilitate this process, Kraken2 was developed to make it faster and computationally less costly (Wood, Lu, and Langmead 2019).\nTo assist those who are new to taxonomic classification activities and even metagenomics, we will describe a brief tutorial here for performing an analysis with Kraken2. It‚Äôs worth noting that all commands shown here are extensively described in the software‚Äôs manual."
  },
  {
    "objectID": "posts/2024-04-04/index.html#building-the-kraken2-database",
    "href": "posts/2024-04-04/index.html#building-the-kraken2-database",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "1. Building the Kraken2 database",
    "text": "1. Building the Kraken2 database\nThe default Kraken2 database can be easily constructed by executing the following command:\n\nkraken2-build --standard --db kraken_standard\n\nYou can speed up some steps by setting the number of threads to use:\n\n# using 30 threads\nkraken2-build --standard --threads 30 --db kraken_standard\n\nThis process will create a directory named ‚Äúkraken_standard‚Äù containing three files: hash.k2d; opts.k2d and taxo.k2d.\nThe Kraken2 standard database is composed by archaea, bacteria, plasmid, viral, UniVec_Core and human databases from GenBank, and should me enough to a basic metagenomics analysis.\n\nNote: Building the standard database will require approximately 500 GB of free space on the hard drive (due to intermediate files) and 80 GB RAM, based on the data downloaded at the time of this publication.\n\n\nTip: rsync connection may crash sometimes. In this case, just run the command again, and Kraken2 will return to the point where the last complete library left off."
  },
  {
    "objectID": "posts/2024-04-04/index.html#classification",
    "href": "posts/2024-04-04/index.html#classification",
    "title": "Basic taxonomic classification of long and short reads with Kraken2",
    "section": "2. Classification",
    "text": "2. Classification\nAfter an extensive database-building job, the time to classify your reads has come. Here I will use the ‚Äúkraken_standard‚Äù created in the last command. You shall change this parameter to the given database that you might be creating.\n\nkraken2 \\\n  --db kraken_standard \\\n  --output kraken_out.txt \\\n  --report kraken_report.txt \\\n  --threads 10 \\\n  gut_unmapped.fastq.gz\n\n--output: Will write the taxonomic classification of each read into the kraken_out.txt file\n--report: Will write the the number of minimizers in the database that are mapped to the various taxa/clades into the kraken_report.txt file. Write this file will be useful for further analysis with Braken, Taxpasta and Krona.\ngut_unmapped.fastq.gz: Are my reads dataset that I want to classify. You may change this parameter to the path and name of the file that you are going to classify."
  },
  {
    "objectID": "posts/2024-03-26/index.html",
    "href": "posts/2024-03-26/index.html",
    "title": "Cholesin: a new hormone discovered for controlling cholesterol levels in humans",
    "section": "",
    "text": "Energy metabolism is one of the most fascinating and complex subjects in human metabolism. For example, cholesterol metabolism involves many different hormones and has a major impact on many diseases, especially cardiovascular diseases. However, apart from being widely studied, pathways involving cholesterol and their effects on human tissues are not completely understood. Recently, a paper published by Hu and collaborators made a major breakthrough in the understanding of the regulation of cholesterol levels (Hu et al. 2024).\nIt is known that cholesterol regulates - and it is regulated by - many genes. The HGM-CoA reductase, the enzyme involved in the first step of the cholesterol synthesis pathway, is downregulated when blood cholesterol levels are high, in a negative feedback mechanism. However, Hu and collaborators observed that the decrease of both RNA and protein levels of HGM-CoA reductase in this scenario is rapidly followed by a recovery of the HGM-CoA reductase, indicating that a new factor can influence the cholesterol synthesis after the cholesterol absorption.\nResearchers were able to isolate a small plasma protein in mice fed with high levels of cholesterol. This protein was related to the human homolog gene C7orf50, which previously had no function associated with it but it is highly conserved between species. They decided to call this protein a new name: cholesin.\nThrough many experiments, researchers showed that cholesin is secreted by enterocytes through a mechanism mediated by NPC1L1 protein, a surface protein in enterocytes involved with cholesterol absorption. Also, they found two specific genetic variations near the end of the cholesin gene that are significantly associated with cholesterol levels in the blood. They studied 600 people and found that higher cholesin levels were linked to lower total and LDL cholesterol levels, but not to HDL cholesterol. Cholesin levels were also negatively associated with triglyceride levels and showed a strong relationship with APOB, a protein associated with cholesterol transport.\n\n\n\nGraphical abstract summarising the main findings from Hu et al, 2024 paper.\n\n\nThese findings suggest that cholesin may play a role in regulating cholesterol levels in the body. This raises new possibilities for the development of new treatments for conditions such as hypercholesterolemia and cardiovascular diseases.\n\n\n\n\nReferences\n\nHu, Xiaoli, Fengyi Chen, Liangjie Jia, Aijun Long, Ying Peng, Xu Li, Junfeng Huang, et al. 2024. ‚ÄúA Gut-Derived Hormone Regulates Cholesterol Metabolism.‚Äù Cell. https://doi.org/https://doi.org/10.1016/j.cell.2024.02.024."
  }
]